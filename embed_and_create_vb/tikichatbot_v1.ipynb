{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvCSZAcvZuHE"
      },
      "outputs": [],
      "source": [
        "!pip install -q qdrant-client pandas pyarrow numpy tqdm sentence-transformers\n",
        "!pip install -q bitsandbytes>=0.46.1 accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdHIQo6zaduH"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import re\n",
        "import unicodedata\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from qdrant_client.models import Filter, FieldCondition, MatchValue, Range, SearchParams\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-eqIye2jQn0"
      },
      "source": [
        "## Qrant connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTDAHlDDZlMO"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "client = QdrantClient(\n",
        "    url=\"xxxxx\",\n",
        "    api_key=\"xxxxxx\",\n",
        ")\n",
        "\n",
        "print(client.get_collections())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6W-ircwjPh5"
      },
      "source": [
        "## Search auto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LbvWbigXZ0ml"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from qdrant_client.http.exceptions import UnexpectedResponse\n",
        "except Exception:\n",
        "    class UnexpectedResponse(Exception):\n",
        "        pass\n",
        "\n",
        "\n",
        "STRICT_CATEGORY = False\n",
        "BRAND_STRICT = False\n",
        "USE_RERANK = True\n",
        "\n",
        "P_HINT = re.compile(\n",
        "    r\"(giá|mua|đặt|kích\\s*thước|dung\\s*tích|màu|model|thương\\s?hiệu|bảo\\s*hành|ml|cm|mm|inch|w|hz|gb|ram|ssd\"\n",
        "    r\"|đồ\\s*chơi|thú\\s*cưng|pet|mèo|chó)\",\n",
        "    re.I,\n",
        ")\n",
        "F_HINT = re.compile(\n",
        "    r\"(cách|hướng\\s*dẫn|làm\\s*sao|làm\\s*thế\\s*nào|quy\\s*định|chính\\s*sách|điều\\s*kiện|đổi\\s*trả|hủy|đăng\\s?k|đăng\\s?nhập|trả\\s*góp|hóa\\s*đơn|vat|bồi\\s*thường|khiếu\\s*nại|xử\\s*lý|vấn\\s*đề|mong\\s*muốn|giải\\s*quyết|bị\\s*lỗi)\",\n",
        "    re.I,\n",
        ")\n",
        "RATING_HINT = re.compile(r\"\\b(\\d(?:\\.\\d)?)\\s*sao\\b|đánh\\s*giá\", re.I)\n",
        "\n",
        "\n",
        "VN_NUM = {\n",
        "    \"k\": 1_000,\n",
        "    \"nghin\": 1_000, \"nghìn\": 1_000,\n",
        "    \"tr\": 1_000_000, \"trieu\": 1_000_000, \"triệu\": 1_000_000,\n",
        "    \"m\": 1_000_000,\n",
        "    \"ty\": 1_000_000_000, \"tỷ\": 1_000_000_000,\n",
        "}\n",
        "\n",
        "RE_PRICE_RANGE = re.compile(\n",
        "    r\"(?:từ|tu)\\s*([0-9\\.\\,]+(?:\\s*\\S+)?)\\s*(?:đến|-|tới)\\s*([0-9\\.\\,]+(?:\\s*\\S+)?)\",\n",
        "    re.I,\n",
        ")\n",
        "\n",
        "RE_PRICE_GTE = re.compile(\n",
        "    r\"(?:>=|>\\s*=?|ít\\s*nhất|tối\\s*thiểu|trên|từ)\\s*([0-9\\.\\,]+(?:\\s*\\S+)?)\",\n",
        "    re.I,\n",
        ")\n",
        "\n",
        "RE_PRICE_LTE = re.compile(\n",
        "    r\"(?:<=|<\\s*=?|tối\\s*đa|max|dưới|không\\s*vượt)\\s*([0-9\\.\\,]+(?:\\s*\\S+)?)\",\n",
        "    re.I,\n",
        ")\n",
        "\n",
        "RE_PRICE_ANY = re.compile(\n",
        "    r\"(?:giá\\s*~?\\s*|≈)?\\s*([0-9\\.\\,]+(?:\\s*\\S+)?)\",\n",
        "    re.I,\n",
        ")\n",
        "\n",
        "\n",
        "RE_RATE_RANGE = re.compile(r\"(\\d(?:\\.\\d)?)\\s*-\\s*(\\d(?:\\.\\d)?)\\s*sao\", re.I)\n",
        "RE_RATE_GTE   = re.compile(r\"(?:>=|trở\\s*lên|từ)\\s*(\\d(?:\\.\\d)?)\\s*sao\", re.I)\n",
        "RE_RATE_LTE   = re.compile(r\"(?:<=|tối\\s*đa|đến|tới|không\\s*quá)\\s*(\\d(?:\\.\\d)?)\\s*sao\", re.I)\n",
        "RE_RATE_ANY   = re.compile(r\"(\\d(?:\\.\\d)?)\\s*sao\", re.I)\n",
        "\n",
        "RE_REV_GTE    = re.compile(r\"(?:>=|từ|ít\\s*nhất)\\s*([0-9]{2,})\\s*(?:đánh\\s*giá|reviews?)\", re.I)\n",
        "\n",
        "\n",
        "CATEGORIES: Dict[str, List[str]] = {\n",
        "    \"Bình giữ nhiệt\": [\"bình giữ nhiệt\", \"binh giu nhiet\", \"thermos\", \"flask\", \"chai giữ nhiệt\"],\n",
        "    \"Balo\": [\"balo\", \"ba lô\", \"backpack\", \"túi đeo lưng\"],\n",
        "}\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    \"\"\"Normalize string: remove diacritics, non-alnum, lowercase\"\"\"\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", s.lower())\n",
        "\n",
        "\n",
        "def _parse_vn_money(s: str) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Parse các dạng:\n",
        "      - 20tr, 20 tr, 20 triệu, 20 trieu\n",
        "      - 500k, 500 k, 500 nghìn, 500 ngàn\n",
        "      - 250.000đ, 250,000 vnd\n",
        "    → trả về int VND\n",
        "    \"\"\"\n",
        "    if not s:\n",
        "        return None\n",
        "\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r\"\\b(vnđ|vnd|đồng)\\b\", \"\", s).strip()\n",
        "\n",
        "    s_ascii = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "\n",
        "    s_ascii = s_ascii.replace(\"đ\", \"\")\n",
        "\n",
        "    s_ascii = s_ascii.replace(\" \", \"\")\n",
        "    s_ascii = s_ascii.replace(\",\", \"\").replace(\".\", \"\")\n",
        "\n",
        "    if not s_ascii:\n",
        "        return None\n",
        "\n",
        "    VN_NUM_ASCII = {\n",
        "        \"k\": 1_000,\n",
        "        \"nghin\": 1_000,\n",
        "        \"ngan\": 1_000,\n",
        "        \"tr\": 1_000_000,\n",
        "        \"trieu\": 1_000_000,\n",
        "        \"m\": 1_000_000,\n",
        "        \"ty\": 1_000_000_000,\n",
        "    }\n",
        "\n",
        "    for suf, mul in VN_NUM_ASCII.items():\n",
        "        if s_ascii.endswith(suf):\n",
        "            num_part = s_ascii[:-len(suf)] or \"0\"\n",
        "            try:\n",
        "                return int(float(num_part) * mul)\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "    try:\n",
        "        return int(float(s_ascii))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def _parse_price_slots(ql: str) -> Tuple[Optional[int], Optional[int]]:\n",
        "    gte = lte = None\n",
        "\n",
        "    if m := RE_PRICE_RANGE.search(ql):\n",
        "        gte, lte = _parse_vn_money(m.group(1)), _parse_vn_money(m.group(2))\n",
        "    if m := RE_PRICE_GTE.search(ql):\n",
        "        gte = _parse_vn_money(m.group(1)) or gte\n",
        "    if m := RE_PRICE_LTE.search(ql):\n",
        "        lte = _parse_vn_money(m.group(1)) or lte\n",
        "\n",
        "    if gte is None and lte is None:\n",
        "        has_price_hint = bool(re.search(\n",
        "            r\"(giá|khoảng|tầm|dưới|trên|<=|>=|tối\\s*đa|tối\\s*thiểu|rẻ|đắt|triệu|tr|nghìn|ngàn|tỷ|vnđ|vnd|đ\\b)\",\n",
        "            ql,\n",
        "            re.I\n",
        "        ))\n",
        "        if has_price_hint:\n",
        "            if m := RE_PRICE_ANY.search(ql):\n",
        "                val = _parse_vn_money(m.group(1))\n",
        "                if val:\n",
        "                    lte = val\n",
        "\n",
        "    return gte, lte\n",
        "\n",
        "\n",
        "\n",
        "def _parse_rating_slots(ql: str) -> Tuple[Optional[float], Optional[float]]:\n",
        "    gte = lte = None\n",
        "    if m := RE_RATE_RANGE.search(ql):\n",
        "        gte, lte = float(m.group(1)), float(m.group(2))\n",
        "    if m := RE_RATE_GTE.search(ql):\n",
        "        gte = float(m.group(1))\n",
        "    if m := RE_RATE_LTE.search(ql):\n",
        "        lte = float(m.group(1))\n",
        "    if gte is None and lte is None:\n",
        "        if m := RE_RATE_ANY.search(ql):\n",
        "            gte = float(m.group(1))\n",
        "    if gte is not None: gte = max(0.0, min(5.0, gte))\n",
        "    if lte is not None: lte = max(0.0, min(5.0, lte))\n",
        "    return gte, lte\n",
        "\n",
        "\n",
        "def resolve_category_syn(q: str) -> Optional[str]:\n",
        "    ql = q.lower()\n",
        "    for cat, syns in CATEGORIES.items():\n",
        "        for s in syns:\n",
        "            if s in ql:\n",
        "                return cat\n",
        "    return None\n",
        "\n",
        "DEDUP_PER_PARENT = 2\n",
        "DEDUP_BY_URL     = True\n",
        "DEDUP_FAQ_NEAR   = True\n",
        "\n",
        "def _norm_sig(s: str) -> str:\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    s = re.sub(r\"[^a-z0-9 ]\", \"\", s)\n",
        "    return s[:180]\n",
        "\n",
        "def dedup_product(df: pd.DataFrame, per_parent: int = DEDUP_PER_PARENT) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    base = df.sort_values([\"score\"], ascending=False)\n",
        "    out = (base.groupby(\"parent_uid\", as_index=False, sort=False).head(per_parent)\n",
        "                .reset_index(drop=True))\n",
        "    if DEDUP_BY_URL and \"url\" in out.columns:\n",
        "        out = out.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "DEDUP_FAQ_PER_PARENT = 2\n",
        "\n",
        "def dedup_faq(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    out = df.copy()\n",
        "\n",
        "    if \"parent_uid\" in out.columns:\n",
        "        out = (\n",
        "            out.sort_values(\"score\", ascending=False)\n",
        "               .groupby(\"parent_uid\", as_index=False, sort=False)\n",
        "               .head(DEDUP_FAQ_PER_PARENT)\n",
        "        )\n",
        "\n",
        "    if DEDUP_BY_URL and \"url\" in out.columns:\n",
        "        out = out.drop_duplicates(subset=[\"url\"])\n",
        "\n",
        "    if DEDUP_FAQ_NEAR and \"text\" in out.columns:\n",
        "        out[\"_sig\"] = out[\"text\"].fillna(\"\").map(_norm_sig)\n",
        "        out = out.drop_duplicates(subset=[\"_sig\"]).drop(columns=[\"_sig\"])\n",
        "\n",
        "    return out.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def dedup_merged(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    if \"url\" in df.columns:\n",
        "        df = df.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def route(query: str) -> str:\n",
        "    q = query or \"\"\n",
        "    try:\n",
        "        p_sig, f_sig = route_strength(q)\n",
        "    except Exception:\n",
        "        p_sig, f_sig = 0, 0\n",
        "\n",
        "    if is_faqish_query(q) or (f_sig > p_sig):\n",
        "        return \"faq\"\n",
        "    if is_productish_query(q) and (p_sig >= f_sig):\n",
        "        return \"product\"\n",
        "    if p_sig >= f_sig + 1:\n",
        "        return \"product\"\n",
        "    if f_sig >= p_sig + 1:\n",
        "        return \"faq\"\n",
        "    return \"both\"\n",
        "\n",
        "def route_strength(q: str) -> tuple[int,int]:\n",
        "    ql = q.lower()\n",
        "    p = len(P_HINT.findall(ql))\n",
        "    f = len(F_HINT.findall(ql))\n",
        "    if RATING_HINT.search(ql): p += 1\n",
        "    if RE_PRICE_GTE.search(ql) or RE_PRICE_LTE.search(ql) or RE_PRICE_ANY.search(ql): p += 1\n",
        "    if re.search(r\"\\bđánh\\s*giá\\b|reviews?\", ql, re.I): p += 1\n",
        "    return p, f\n",
        "\n",
        "\n",
        "def embed_query(q: str) -> np.ndarray:\n",
        "    return q_model.encode([q], convert_to_numpy=True, normalize_embeddings=True)[0].astype(\"float32\")\n",
        "\n",
        "def parse_slots(query: str, known_brands: Optional[List[str]] = None) -> Dict[str, Optional[object]]:\n",
        "    out = {\n",
        "        \"category\": None,\n",
        "        \"brand\": None,\n",
        "        \"price_gte\": None,\n",
        "        \"price_lte\": None,\n",
        "        \"rating_gte\": None,\n",
        "        \"rating_lte\": None,\n",
        "        \"reviews_gte\": None,\n",
        "    }\n",
        "    ql = query.lower()\n",
        "    qn = _norm(query)\n",
        "    out[\"category\"] = resolve_category_syn(ql)\n",
        "    if known_brands:\n",
        "        nb = {b: _norm(b) for b in known_brands}\n",
        "        for b, bn in nb.items():\n",
        "            if bn and bn in qn:\n",
        "                out[\"brand\"] = b\n",
        "                break\n",
        "\n",
        "    pg, pl = _parse_price_slots(ql)\n",
        "    out[\"price_gte\"], out[\"price_lte\"] = pg, pl\n",
        "\n",
        "    rg, rl = _parse_rating_slots(ql)\n",
        "    out[\"rating_gte\"], out[\"rating_lte\"] = rg, rl\n",
        "\n",
        "    if m := RE_REV_GTE.search(ql):\n",
        "        try:\n",
        "            out[\"reviews_gte\"] = int(m.group(1))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return out\n",
        "\n",
        "def build_filter(\n",
        "    category: Optional[str] = None,\n",
        "    brands: Optional[List[str]] = None,\n",
        "    parent_uid: Optional[str] = None,\n",
        "    dtype: Optional[str] = None,\n",
        "    price_gte: Optional[float] = None,\n",
        "    price_lte: Optional[float] = None,\n",
        "    rating_gte: Optional[float] = None,\n",
        "    rating_lte: Optional[float] = None,\n",
        "    review_count_gte: Optional[int] = None,\n",
        "    review_count_lte: Optional[int] = None,\n",
        ") -> Optional[Filter]:\n",
        "    must, should, must_not = [], [], []\n",
        "\n",
        "    if category:\n",
        "        should.append(FieldCondition(key=\"category\", match=MatchValue(value=category)))\n",
        "\n",
        "    if brands:\n",
        "        brands = [b for b in brands if b]\n",
        "        if brands:\n",
        "            should.extend([FieldCondition(key=\"brand\", match=MatchValue(value=b)) for b in brands])\n",
        "\n",
        "    if parent_uid:\n",
        "        must.append(FieldCondition(key=\"parent_uid\", match=MatchValue(value=parent_uid)))\n",
        "    if dtype:\n",
        "        must.append(FieldCondition(key=\"type\", match=MatchValue(value=dtype)))\n",
        "\n",
        "    if price_gte is not None or price_lte is not None:\n",
        "        must.append(FieldCondition(key=\"price_numeric\", range=Range(gte=price_gte, lte=price_lte)))\n",
        "    if rating_gte is not None or rating_lte is not None:\n",
        "        must.append(FieldCondition(key=\"rating\", range=Range(gte=rating_gte, lte=rating_lte)))\n",
        "    if review_count_gte is not None or review_count_lte is not None:\n",
        "        must.append(FieldCondition(key=\"review_count\", range=Range(gte=review_count_gte, lte=review_count_lte)))\n",
        "\n",
        "    if not (must or should or must_not):\n",
        "        return None\n",
        "    return Filter(must=must, should=should, must_not=must_not)\n",
        "\n",
        "\n",
        "\n",
        "DEF_COLS = [\n",
        "    \"id\",\"point_id\",\"score\",\"title\",\"category\",\"url\",\"type\",\"parent_uid\",\n",
        "    \"brand\",\"thumbnail\",\"price\",\"rating\",\"reviews\",\"source\",\"text\"\n",
        "]\n",
        "\n",
        "def qdrant_search(client, collection: str, qv: np.ndarray, topk: int = 8,\n",
        "                  flt: Optional[Filter] = None, hnsw_ef: int = 128) -> pd.DataFrame:\n",
        "    res = client.query_points(\n",
        "        collection_name=collection,\n",
        "        query=qv,\n",
        "        limit=topk,\n",
        "        query_filter=flt,\n",
        "        search_params=SearchParams(hnsw_ef=hnsw_ef),\n",
        "        with_payload=True,\n",
        "        with_vectors=False,\n",
        "    )\n",
        "    points = getattr(res, \"points\", res)\n",
        "\n",
        "    rows = []\n",
        "    for p in points or []:\n",
        "        pl = getattr(p, \"payload\", None) or {}\n",
        "        rows.append({\n",
        "            \"id\":         pl.get(\"id\") or \"\",\n",
        "            \"point_id\":   str(getattr(p, \"id\", \"\")),\n",
        "            \"score\":      float(getattr(p, \"score\", 0.0)),\n",
        "            \"title\":      pl.get(\"title\"),\n",
        "            \"category\":   pl.get(\"category\"),\n",
        "            \"url\":        pl.get(\"url\"),\n",
        "            \"type\":       pl.get(\"type\"),\n",
        "            \"parent_uid\": pl.get(\"parent_uid\"),\n",
        "            \"brand\":      pl.get(\"brand\"),\n",
        "            \"thumbnail\":  pl.get(\"thumbnail\"),\n",
        "            \"price\":      pl.get(\"price_numeric\"),\n",
        "            \"rating\":     pl.get(\"rating\"),\n",
        "            \"reviews\":    pl.get(\"review_count\"),\n",
        "            \"source\":     collection,\n",
        "            \"text\":       pl.get(\"text\"),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=DEF_COLS)\n",
        "    if df.empty:\n",
        "        return df\n",
        "    return df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def _rerank(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty or (\"rating\" not in df.columns) or (\"reviews\" not in df.columns):\n",
        "        return df\n",
        "    r = pd.to_numeric(df[\"rating\"], errors=\"coerce\").fillna(0.0)\n",
        "    v = pd.to_numeric(df[\"reviews\"], errors=\"coerce\").fillna(0.0)\n",
        "    s = pd.to_numeric(df[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "    rerank = s * (1.0 + 0.02 * r) * (1.0 + 0.001 * np.log1p(v))\n",
        "    df = df.assign(_rerank=rerank)\n",
        "    return df.sort_values([\"_rerank\", \"score\"], ascending=False).drop(columns=[\"_rerank\"]).reset_index(drop=True)\n",
        "\n",
        "def search_auto(\n",
        "    client,\n",
        "    query: str,\n",
        "    topk: int = 8,\n",
        "    category: Optional[str] = None,\n",
        "    brand: Optional[str] = None,\n",
        "    brands: Optional[List[str]] = None,\n",
        "    price_gte: Optional[float] = None,\n",
        "    price_lte: Optional[float] = None,\n",
        "    rating_gte: Optional[float] = None,\n",
        "    rating_lte: Optional[float] = None,\n",
        "    review_count_gte: Optional[int] = None,\n",
        "    parent_uid: Optional[str] = None,\n",
        ") -> Tuple[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Returns: (target, DataFrame)\n",
        "      target ∈ {\"product\",\"faq\",\"both\"}\n",
        "    \"\"\"\n",
        "    print(f\"[Brand] {brand}\")\n",
        "    print(f\"[Brands] {brands}\")\n",
        "    print(f\"[search_auto] price_gte={price_gte}, price_lte={price_lte}\")\n",
        "    slots_q = parse_slots(query)\n",
        "    if price_gte is None and slots_q.get(\"price_gte\") is not None:\n",
        "        price_gte = slots_q[\"price_gte\"]\n",
        "    if price_lte is None and slots_q.get(\"price_lte\") is not None:\n",
        "        price_lte = slots_q[\"price_lte\"]\n",
        "\n",
        "    if rating_gte is None and slots_q.get(\"rating_gte\") is not None:\n",
        "        rating_gte = slots_q[\"rating_gte\"]\n",
        "    if rating_lte is None and slots_q.get(\"rating_lte\") is not None:\n",
        "        rating_lte = slots_q[\"rating_lte\"]\n",
        "    if review_count_gte is None and slots_q.get(\"reviews_gte\") is not None:\n",
        "        review_count_gte = slots_q[\"reviews_gte\"]\n",
        "    target = route(query)\n",
        "    qv = embed_query(query)\n",
        "    brand_list = brands if brands else ([brand] if brand else None)\n",
        "\n",
        "    cond_product = build_filter(\n",
        "        category=None,\n",
        "        brands=None,\n",
        "        parent_uid=parent_uid,\n",
        "        dtype=None,\n",
        "        price_gte=price_gte,\n",
        "        price_lte=price_lte,\n",
        "        rating_gte=rating_gte,\n",
        "        rating_lte=rating_lte,\n",
        "        review_count_gte=review_count_gte,\n",
        "    )\n",
        "    cond_faq = build_filter(\n",
        "        category=category,\n",
        "        brands=brand_list,\n",
        "        parent_uid=parent_uid,\n",
        "        dtype=None,\n",
        "    )\n",
        "\n",
        "    def search_with_fallback(collection: str, cond: Optional[Filter]) -> pd.DataFrame:\n",
        "        try:\n",
        "            df = qdrant_search(client, collection, qv, topk, cond)\n",
        "        except UnexpectedResponse:\n",
        "            df = qdrant_search(client, collection, qv, topk, flt=None)\n",
        "\n",
        "        if df.empty:\n",
        "            if collection == \"product_bge\":\n",
        "                cond_relaxed = build_filter(parent_uid=parent_uid)\n",
        "            else:\n",
        "                cond_relaxed = None\n",
        "            df = qdrant_search(client, collection, qv, topk, cond_relaxed)\n",
        "            if df.empty:\n",
        "                df = qdrant_search(client, collection, qv, topk, flt=None)\n",
        "\n",
        "        if collection == \"product_bge\":\n",
        "            if USE_RERANK:\n",
        "                df = _rerank(df)\n",
        "            df = dedup_product(df, per_parent=DEDUP_PER_PARENT)\n",
        "        elif collection == \"faq_bge\":\n",
        "            if not df.empty:\n",
        "                df[\"score\"] = df[\"score\"] * 1.2\n",
        "            df = dedup_faq(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    p_sig, f_sig = route_strength(query)\n",
        "\n",
        "    if target == \"faq\":\n",
        "        return \"faq\", search_with_fallback(\"faq_bge\", cond_faq)\n",
        "\n",
        "    if target == \"both\" and f_sig >= p_sig + 1:\n",
        "        a = search_with_fallback(\"faq_bge\", cond_faq)\n",
        "        return \"faq\", a\n",
        "\n",
        "    if target == \"product\":\n",
        "        return \"product\", search_with_fallback(\"product_bge\", cond_product)\n",
        "\n",
        "    a = search_with_fallback(\"faq_bge\", cond_faq)\n",
        "    b = search_with_fallback(\"product_bge\", cond_product)\n",
        "\n",
        "    merged = pd.concat([a, b], ignore_index=True)\n",
        "    merged = dedup_merged(merged)\n",
        "    merged = merged.sort_values(\"score\", ascending=False).head(topk).reset_index(drop=True)\n",
        "    return \"both\", merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oOT92OtkQWI"
      },
      "source": [
        "## BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLxd1mh9e_3J"
      },
      "outputs": [],
      "source": [
        "def read_jsonl_strict(path: str) -> pd.DataFrame:\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Không thấy file: {path}\")\n",
        "    try:\n",
        "        return pd.read_json(p, lines=True)\n",
        "    except Exception as e:\n",
        "        print(f\"[read_jsonl_strict] thất bại, chuyển parser thủ công. Lý do: {e}\")\n",
        "\n",
        "    rows, bad = [], 0\n",
        "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, start=1):\n",
        "            s = line.strip()\n",
        "            if not s:\n",
        "                continue\n",
        "            try:\n",
        "                rows.append(json.loads(s))\n",
        "            except Exception as ex:\n",
        "                bad += 1\n",
        "                snip = s[:180].replace(\"\\n\",\" \")\n",
        "                print(f\"Bỏ qua dòng {i}: {ex} | {snip}\")\n",
        "    if not rows:\n",
        "        raise ValueError(f\"File '{path}' không hợp lệ.\")\n",
        "    print(f\"[read_jsonl_strict] Done: {len(rows)} dòng hợp lệ, {bad} dòng lỗi.\")\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def _safe_meta(obj):\n",
        "    m = obj.get(\"meta\", {})\n",
        "    if isinstance(m, str):\n",
        "        try:\n",
        "            m = json.loads(m)\n",
        "        except Exception:\n",
        "            m = {}\n",
        "    return m if isinstance(m, dict) else {}\n",
        "\n",
        "ID_RE_MIDDLE = re.compile(r\"^product::([^:]+)(?:::\\d+)?$\")\n",
        "ID_RE_HASH_ONLY = re.compile(r\"^product::([^:]+)\")\n",
        "TAIL_NUM = re.compile(r\"(\\d+)$\")\n",
        "\n",
        "def parent_from_chunk_id(chunk_id: str):\n",
        "    if not isinstance(chunk_id, str):\n",
        "        return None\n",
        "    m = ID_RE_HASH_ONLY.match(chunk_id)\n",
        "    return f\"product::{m.group(1)}\" if m else None\n",
        "\n",
        "def extract_source_id(row):\n",
        "    m = _safe_meta(row)\n",
        "    sid = m.get(\"source_id\")\n",
        "    if sid:\n",
        "        return str(sid)\n",
        "    pu = str(row.get(\"parent_uid\", \"\"))\n",
        "    t = TAIL_NUM.search(pu)\n",
        "    return t.group(1) if t else None\n",
        "\n",
        "def build_parent_lookup(jsonl_path: str) -> dict:\n",
        "    df = read_jsonl_strict(jsonl_path)\n",
        "    for c in [\"id\", \"parent_uid\", \"meta\"]:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "\n",
        "    df[\"_source_id\"] = df.apply(extract_source_id, axis=1)\n",
        "    df[\"_parent_qdrant\"] = df[\"id\"].map(parent_from_chunk_id)\n",
        "\n",
        "    lk = (\n",
        "        df.dropna(subset=[\"_source_id\", \"_parent_qdrant\"])\n",
        "          .drop_duplicates(subset=[\"_source_id\"])\n",
        "          .set_index(\"_source_id\")[\"_parent_qdrant\"]\n",
        "          .to_dict()\n",
        "    )\n",
        "\n",
        "    df[\"_tail_num\"] = df[\"parent_uid\"].apply(\n",
        "        lambda s: (TAIL_NUM.search(str(s)).group(1) if s else None)\n",
        "    )\n",
        "    tmp = (\n",
        "        df.dropna(subset=[\"_tail_num\", \"_parent_qdrant\"])\n",
        "          .drop_duplicates(subset=[\"_tail_num\"])\n",
        "          .set_index(\"_tail_num\")[\"_parent_qdrant\"]\n",
        "          .to_dict()\n",
        "    )\n",
        "    for k, v in tmp.items():\n",
        "        lk.setdefault(k, v)\n",
        "\n",
        "    print(f\"[build_parent_lookup] entries: {len(lk)}\")\n",
        "    for probe in (\"104270135\",):\n",
        "        print(\"check\", probe, \"---\", lk.get(probe))\n",
        "    return lk\n",
        "\n",
        "def normalize_parent_for_qdrant(pid: str) -> str:\n",
        "    if not pid:\n",
        "        return \"\"\n",
        "    m = ID_RE_HASH_ONLY.match(pid)\n",
        "    if m:\n",
        "        return f\"product::{m.group(1)}\"\n",
        "    t = TAIL_NUM.search(str(pid))\n",
        "    if not t:\n",
        "        return pid\n",
        "    sid = t.group(1)\n",
        "    return parent_lookup.get(sid, pid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7nlll5vl3sh"
      },
      "outputs": [],
      "source": [
        "def strip_accents(s: str) -> str:\n",
        "    return unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "\n",
        "def normalize_text_for_sparse(s: str) -> str:\n",
        "    s = strip_accents(str(s)).lower()\n",
        "    s = re.sub(r\"[^\\w\\s\\-\\%\\./]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def tokenize(s: str) -> List[str]:\n",
        "    s = normalize_text_for_sparse(s)\n",
        "    toks = s.split()\n",
        "    out = []\n",
        "    for t in toks:\n",
        "        if len(t) == 1 and not t.isdigit():\n",
        "            continue\n",
        "        out.append(t)\n",
        "    return out\n",
        "\n",
        "\n",
        "class BM25Okapi:\n",
        "    def __init__(self, corpus_tokens: List[List[str]], k1: float = 1.5, b: float = 0.75, epsilon: float = 0.25):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.corpus_size = len(corpus_tokens)\n",
        "        self.doc_len = np.array([len(doc) for doc in corpus_tokens], dtype=np.float32)\n",
        "        self.avgdl = float(self.doc_len.mean()) if self.corpus_size else 0.0\n",
        "\n",
        "        self.term_freqs: List[Dict[str, int]] = []\n",
        "        self.doc_freqs: Dict[str, int] = {}\n",
        "        for doc in corpus_tokens:\n",
        "            tf: Dict[str, int] = {}\n",
        "            for w in doc:\n",
        "                tf[w] = tf.get(w, 0) + 1\n",
        "            self.term_freqs.append(tf)\n",
        "            for w in tf.keys():\n",
        "                self.doc_freqs[w] = self.doc_freqs.get(w, 0) + 1\n",
        "\n",
        "        self.idf: Dict[str, float] = {}\n",
        "        for w, df in self.doc_freqs.items():\n",
        "            val = math.log((self.corpus_size - df + 0.5) / (df + 0.5) + 1e-9)\n",
        "            if val < 0:\n",
        "                val *= self.epsilon\n",
        "            self.idf[w] = val\n",
        "\n",
        "    def get_scores(self, query_tokens: List[str]) -> np.ndarray:\n",
        "        scores = np.zeros(self.corpus_size, dtype=np.float32)\n",
        "        if self.corpus_size == 0:\n",
        "            return scores\n",
        "        for w in query_tokens:\n",
        "            if w not in self.idf:\n",
        "                continue\n",
        "            idf = self.idf[w]\n",
        "            for i, tf in enumerate(self.term_freqs):\n",
        "                f = tf.get(w, 0)\n",
        "                if f == 0:\n",
        "                    continue\n",
        "                denom = f + self.k1 * (1 - self.b + self.b * (self.doc_len[i] / (self.avgdl or 1.0)))\n",
        "                scores[i] += idf * (f * (self.k1 + 1)) / (denom + 1e-9)\n",
        "        return scores\n",
        "\n",
        "\n",
        "class ParentBM25Index:\n",
        "    def __init__(self, k1: float = 1.5, b: float = 0.75, epsilon: float = 0.25):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.parents: List[str] = []\n",
        "        self.meta: Dict[str, Dict[str, Any]] = {}\n",
        "        self.docs_tokens: List[List[str]] = []\n",
        "        self._bm25: Optional[BM25Okapi] = None\n",
        "\n",
        "    def fit(self, parent_rows: Dict[str, Dict[str, Any]]):\n",
        "        self.parents.clear()\n",
        "        self.meta = {}\n",
        "        self.docs_tokens.clear()\n",
        "\n",
        "        for pid, info in parent_rows.items():\n",
        "            ts = (info.get(\"text_sparse_parent\") or \"\").strip()\n",
        "            if not ts:\n",
        "                continue\n",
        "            self.parents.append(pid)\n",
        "            self.meta[pid] = info\n",
        "            self.docs_tokens.append(tokenize(ts))\n",
        "\n",
        "        self._bm25 = BM25Okapi(self.docs_tokens, k1=self.k1, b=self.b, epsilon=self.epsilon)\n",
        "\n",
        "    def is_ready(self) -> bool:\n",
        "        return (self._bm25 is not None) and (len(self.parents) == len(self.docs_tokens) > 0)\n",
        "\n",
        "    def search(self, query: str, topk: int = 20) -> pd.DataFrame:\n",
        "\n",
        "        if not self.is_ready():\n",
        "            return pd.DataFrame(columns=[\"parent_uid\",\"score\",\"brand\",\"category_norm\",\"kv_compact\"])\n",
        "\n",
        "        q_tokens = tokenize(query)\n",
        "        scores = self._bm25.get_scores(q_tokens)\n",
        "\n",
        "        k = min(topk, len(scores))\n",
        "        idx = np.argpartition(-scores, kth=k-1)[:k]\n",
        "        idx = idx[np.argsort(-scores[idx])]\n",
        "\n",
        "        rows = []\n",
        "        for i in idx:\n",
        "            pid = self.parents[i]\n",
        "            m = self.meta.get(pid, {})\n",
        "            rows.append({\n",
        "                \"parent_uid\": pid,\n",
        "                \"score\": float(scores[i]),\n",
        "                \"brand\": m.get(\"brand\"),\n",
        "                \"category_norm\": m.get(\"category_norm\"),\n",
        "                \"kv_compact\": m.get(\"kv_compact\"),\n",
        "            })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    def save(self, folder: str):\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        with open(os.path.join(folder, \"parents.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(self.parents, f)\n",
        "        with open(os.path.join(folder, \"docs_tokens.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(self.docs_tokens, f)\n",
        "        with open(os.path.join(folder, \"meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(self.meta, f, ensure_ascii=False, indent=2)\n",
        "        with open(os.path.join(folder, \"params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\"k1\": self.k1, \"b\": self.b, \"epsilon\": self.epsilon}, f)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, folder: str) -> \"ParentBM25Index\":\n",
        "        with open(os.path.join(folder, \"params.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "            p = json.load(f)\n",
        "        obj = cls(k1=p.get(\"k1\", 1.5), b=p.get(\"b\", 0.75), epsilon=p.get(\"epsilon\", 0.25))\n",
        "        with open(os.path.join(folder, \"parents.pkl\"), \"rb\") as f:\n",
        "            obj.parents = pickle.load(f)\n",
        "        with open(os.path.join(folder, \"docs_tokens.pkl\"), \"rb\") as f:\n",
        "            obj.docs_tokens = pickle.load(f)\n",
        "        with open(os.path.join(folder, \"meta.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "            obj.meta = json.load(f)\n",
        "        obj._bm25 = BM25Okapi(obj.docs_tokens, k1=obj.k1, b=obj.b, epsilon=obj.epsilon)\n",
        "        return obj\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrHdVHjSkq8C"
      },
      "source": [
        "## Search hybrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyJFQ1LiPzw1"
      },
      "outputs": [],
      "source": [
        "TAIL_NUM = re.compile(r\"(\\d+)$\")\n",
        "ID_RE_MIDDLE = re.compile(r\"^product::([^:]+)(?:::\\d+)?$\")\n",
        "\n",
        "def _norm_sparse_query(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"[^\\w\\s\\-\\%\\./]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def normalize_parent_for_qdrant(pid: str, parent_lookup: dict) -> str:\n",
        "    if not pid:\n",
        "        return \"\"\n",
        "    m = ID_RE_MIDDLE.match(pid)\n",
        "    if m:\n",
        "        return f\"product::{m.group(1)}::0\"\n",
        "    m2 = TAIL_NUM.search(str(pid))\n",
        "    if not m2:\n",
        "        return pid\n",
        "    sid = m2.group(1)\n",
        "    return parent_lookup.get(sid, pid)\n",
        "\n",
        "def _parent_key_for_sparse(pid: str) -> str:\n",
        "    m = TAIL_NUM.search(str(pid))\n",
        "    return m.group(1) if m else str(pid)\n",
        "\n",
        "def _parent_key_for_dense(pid: str, parent_lookup_rev: dict) -> str:\n",
        "    if isinstance(pid, str):\n",
        "        m = ID_RE_MIDDLE.match(pid)\n",
        "        if m:\n",
        "            pid0 = f\"product::{m.group(1)}::0\"\n",
        "            if pid0 in parent_lookup_rev:\n",
        "                return parent_lookup_rev[pid0]\n",
        "    if pid in parent_lookup_rev:\n",
        "        return parent_lookup_rev[pid]\n",
        "    m = TAIL_NUM.search(str(pid))\n",
        "    return m.group(1) if m else str(pid)\n",
        "\n",
        "RE_FAQ_HINTS = re.compile(\n",
        "    r\"(thanh\\s*to[aá]n|payment|momo|zalopay|atm|visa|master\\s*card|\"\n",
        "    r\"tr[aả]\\s*g[oó]p|installment|paylater|tr[aả]\\s*sau|\"\n",
        "    r\"ho[aà]n\\s*ti[eề]n|refund|\"\n",
        "    r\"\\b(?:[đd]ổi|doi)\\s*tr[aả]|return|exchange|\"\n",
        "    r\"b[ảa]o\\s*h[aà]nh|warranty|\"\n",
        "    r\"giao\\s*h[aà]ng|v[ậa]n\\s*chuy[eể]n|ph[ií]\\s*ship|\"\n",
        "    r\"h[ủu]y\\s*đ[ơo]n|cancel\\s*order|\"\n",
        "    r\"tr[aạ]ng\\s*th[aá]i\\s*đ[ơo]n|order\\s*status|\"\n",
        "    r\"v[ơô]ucher|m[aã]\\s*gi[ảa]m\\s*gi[aá]|coupon|xu\\s*tiki|\"\n",
        "    r\"l[aắ]p\\s*đ[ặa]t|installation|\"\n",
        "    r\"t[aà]i\\s*kho[aả]n|login|[đd][ăă]ng\\s*nh[aâ]p|\"\n",
        "    r\"li[êe]n\\s*h[eệ]|ch[aă]m\\s*s[oóc]c\\s*k[hà]ch\\s*h[aà]ng)\",\n",
        "    re.I\n",
        ")\n",
        "\n",
        "def is_faqish_query(q: str) -> bool:\n",
        "    return bool(RE_FAQ_HINTS.search(q))\n",
        "\n",
        "RE_TECH_UNITS = re.compile(r\"(ml|l|mm|cm|inch|\\\"|hz|w|gb|tb|mah)\\b\", re.I)\n",
        "\n",
        "def is_productish_query(q: str) -> bool:\n",
        "    ql = q.lower()\n",
        "    try:\n",
        "        if resolve_category_syn(ql):\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    if RE_TECH_UNITS.search(ql):\n",
        "        return True\n",
        "    if re.search(r\"\\b[A-Z0-9]{3,}[-_\\.]?[A-Z0-9]{2,}\\b\", unicodedata.normalize(\"NFKD\", q), re.I):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def _aggregate_dense_by_parent(df_chunks: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df_chunks.empty or \"parent_uid\" not in df_chunks.columns or \"score\" not in df_chunks.columns:\n",
        "        return pd.DataFrame(columns=[\"parent_uid\", \"score_dense_parent\"])\n",
        "    d = df_chunks[[\"parent_uid\", \"score\"]].copy()\n",
        "    d[\"score\"] = pd.to_numeric(d[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "    top2 = (\n",
        "        d.sort_values([\"parent_uid\", \"score\"], ascending=[True, False])\n",
        "        .groupby(\"parent_uid\")[\"score\"]\n",
        "        .apply(lambda s: list(s.head(2)))\n",
        "        .reset_index(name=\"_scores\")\n",
        "    )\n",
        "    def _combine(scores):\n",
        "        if not scores:\n",
        "            return 0.0\n",
        "        return float(scores[0]) + (0.05 * float(scores[1]) if len(scores) > 1 else 0.0)\n",
        "    top2[\"score_dense_parent\"] = top2[\"_scores\"].apply(_combine)\n",
        "    return top2[[\"parent_uid\", \"score_dense_parent\"]]\n",
        "\n",
        "def _fuse_parent_rrf(\n",
        "    df_dense_parent: pd.DataFrame,\n",
        "    df_sparse_parent: pd.DataFrame,\n",
        "    parent_lookup_rev: dict,\n",
        "    topk: int = 12,\n",
        "    k: int = 60,\n",
        "    lam: float = 0.8,\n",
        ") -> pd.DataFrame:\n",
        "    if df_dense_parent is None or df_dense_parent.empty:\n",
        "        D = pd.DataFrame(columns=[\"parent_uid\", \"score_dense_parent\"])\n",
        "    else:\n",
        "        D = df_dense_parent.copy()\n",
        "        D = D[[\"parent_uid\", \"score_dense_parent\"]].copy()\n",
        "        D[\"score_dense_parent\"] = pd.to_numeric(D[\"score_dense_parent\"], errors=\"coerce\").fillna(0.0)\n",
        "        D = D.sort_values(\"score_dense_parent\", ascending=False).reset_index(drop=True)\n",
        "        D[\"_pid_key\"] = D[\"parent_uid\"].map(lambda x: _parent_key_for_dense(x, parent_lookup_rev))\n",
        "        D[\"_rank_dense\"] = np.arange(len(D), dtype=float)\n",
        "\n",
        "    if df_sparse_parent is None or df_sparse_parent.empty:\n",
        "        S = pd.DataFrame(columns=[\"parent_uid\", \"score\"])\n",
        "    else:\n",
        "        S = df_sparse_parent.copy()\n",
        "        S = S[[\"parent_uid\", \"score\"]].copy()\n",
        "        S[\"score\"] = pd.to_numeric(S[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "        S = S.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "        S[\"_pid_key\"] = S[\"parent_uid\"].map(_parent_key_for_sparse)\n",
        "        S[\"_rank_sparse\"] = np.arange(len(S), dtype=float)\n",
        "\n",
        "    if D.empty and S.empty:\n",
        "        return pd.DataFrame(columns=[\"parent_uid\", \"_rrf\", \"rank\", \"_pid_key\"])\n",
        "\n",
        "    if D.empty and not S.empty:\n",
        "        M = S.copy()\n",
        "        M[\"_rank_dense\"] = np.inf\n",
        "        M[\"parent_uid\"] = M[\"parent_uid\"]\n",
        "    else:\n",
        "        if S.empty:\n",
        "            M = D.copy()\n",
        "            M[\"_rank_sparse\"] = np.inf\n",
        "        else:\n",
        "            M = pd.merge(\n",
        "                D[[\"_pid_key\", \"_rank_dense\", \"parent_uid\"]].rename(\n",
        "                    columns={\"parent_uid\": \"parent_uid_dense\"}\n",
        "                ),\n",
        "                S[[\"_pid_key\", \"_rank_sparse\"]],\n",
        "                on=\"_pid_key\",\n",
        "                how=\"left\",\n",
        "            )\n",
        "            M[\"parent_uid\"] = M[\"parent_uid_dense\"]\n",
        "            M.drop(columns=[\"parent_uid_dense\"], inplace=True)\n",
        "\n",
        "    M[\"_rank_dense\"] = M.get(\"_rank_dense\", np.inf).astype(float)\n",
        "    M[\"_rank_sparse\"] = M.get(\"_rank_sparse\", np.inf).astype(float)\n",
        "\n",
        "    M[\"_rrf\"] = (1.0 / (k + M[\"_rank_dense\"])) + lam * (1.0 / (k + M[\"_rank_sparse\"]))\n",
        "    M = M.sort_values(\"_rrf\", ascending=False).head(topk).reset_index(drop=True)\n",
        "    M[\"rank\"] = np.arange(len(M))\n",
        "    M[\"_pid_key\"] = M[\"_pid_key\"].astype(str)\n",
        "\n",
        "    return M[[\"parent_uid\", \"_rrf\", \"rank\", \"_pid_key\"]]\n",
        "\n",
        "def _fetch_best_chunks_for_parent(\n",
        "    client,\n",
        "    qv: np.ndarray,\n",
        "    parent_uid: str,\n",
        "    take: int = 2,\n",
        "    price_gte: Optional[float] = None,\n",
        "    price_lte: Optional[float] = None\n",
        ") -> pd.DataFrame:\n",
        "    if not parent_uid:\n",
        "        return pd.DataFrame()\n",
        "    flt = build_filter(parent_uid=parent_uid, price_gte=price_gte, price_lte=price_lte)\n",
        "    try:\n",
        "        return qdrant_search(client, \"product_bge\", qv, topk=take, flt=flt)\n",
        "    except Exception:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def search_auto_hybrid(\n",
        "    client,\n",
        "    bm25_index,\n",
        "    query: str,\n",
        "    topk: int = 8,\n",
        "    category: Optional[str] = None,\n",
        "    brand: Optional[str] = None,\n",
        "    brands: Optional[List[str]] = None,\n",
        "    price_gte: Optional[float] = None,\n",
        "    price_lte: Optional[float] = None,\n",
        "    rating_gte: Optional[float] = None,\n",
        "    rating_lte: Optional[float] = None,\n",
        "    review_count_gte: Optional[int] = None,\n",
        "    parent_uid: Optional[str] = None,\n",
        "    dense_topk_chunks: int = 48,\n",
        "    bm25_topk_parents: int = 50,\n",
        "    rrf_k: int = 60,\n",
        "    rrf_lambda: float = 0.8,\n",
        "    per_parent_chunks: int = 2,\n",
        "    parent_lookup: Optional[dict] = None,\n",
        "    parent_lookup_rev: Optional[dict] = None,\n",
        "    verbose: bool = True,\n",
        ") -> Tuple[str, pd.DataFrame]:\n",
        "\n",
        "    if parent_lookup is None or parent_lookup_rev is None:\n",
        "        raise ValueError(\"Cần truyền parent_lookup và parent_lookup_rev (đã build từ JSONL)\")\n",
        "\n",
        "    def _dbg(msg: str):\n",
        "        if verbose:\n",
        "            print(msg)\n",
        "\n",
        "    def _peek(df: pd.DataFrame, cols: List[str], n: int = 3, title: str = \"\"):\n",
        "        if not verbose:\n",
        "            return\n",
        "        if title:\n",
        "            print(title)\n",
        "        if df is None or df.empty:\n",
        "            print(\"  (empty)\")\n",
        "        else:\n",
        "            cols_eff = [c for c in cols if c in df.columns]\n",
        "            print(df[cols_eff].head(n).to_string(index=False))\n",
        "\n",
        "    target = route(query)\n",
        "    p_sig, f_sig = route_strength(query)\n",
        "    _dbg(f\"Route(raw)={target} | productish={is_productish_query(query)} | faqish={is_faqish_query(query)} | signals p={p_sig}, f={f_sig}\")\n",
        "\n",
        "    slots_q = parse_slots(query)\n",
        "    if price_gte is None and slots_q.get(\"price_gte\") is not None:\n",
        "        price_gte = slots_q[\"price_gte\"]\n",
        "    if price_lte is None and slots_q.get(\"price_lte\") is not None:\n",
        "        price_lte = slots_q[\"price_lte\"]\n",
        "    if rating_gte is None and slots_q.get(\"rating_gte\") is not None:\n",
        "        rating_gte = slots_q[\"rating_gte\"]\n",
        "    if rating_lte is None and slots_q.get(\"rating_lte\") is not None:\n",
        "        rating_lte = slots_q[\"rating_lte\"]\n",
        "    if review_count_gte is None and slots_q.get(\"reviews_gte\") is not None:\n",
        "        review_count_gte = slots_q[\"reviews_gte\"]\n",
        "    _dbg(f\"Params: topk={topk}, dense_topk_chunks={dense_topk_chunks}, bm25_topk_parents={bm25_topk_parents}, rrf_k={rrf_k}, rrf_lambda={rrf_lambda}, per_parent_chunks={per_parent_chunks}\")\n",
        "    if price_gte is not None or price_lte is not None:\n",
        "        _dbg(f\"Price filter: gte={price_gte} | lte={price_lte}\")\n",
        "\n",
        "    qv = embed_query(query)\n",
        "    brand_list = brands if brands else ([brand] if brand else None)\n",
        "\n",
        "    cond_product = build_filter(\n",
        "        category=None,\n",
        "        brands=None,\n",
        "        parent_uid=parent_uid,\n",
        "        dtype=None,\n",
        "        price_gte=price_gte,\n",
        "        price_lte=price_lte,\n",
        "        rating_gte=rating_gte,\n",
        "        rating_lte=rating_lte,\n",
        "        review_count_gte=review_count_gte,\n",
        "    )\n",
        "    cond_faq = build_filter(category=None, brands=None, parent_uid=None, dtype=None)\n",
        "\n",
        "    def search_with_fallback(collection: str, cond, _topk: int) -> pd.DataFrame:\n",
        "        try:\n",
        "            df = qdrant_search(client, collection, qv, _topk, cond)\n",
        "            _dbg(f\"Qdrant[{collection}] first try: {len(df)}\")\n",
        "        except Exception:\n",
        "            _dbg(f\"Qdrant[{collection}] error - retry no-filter\")\n",
        "            df = qdrant_search(client, collection, qv, _topk, flt=None)\n",
        "\n",
        "        if df.empty:\n",
        "            if collection == \"product_bge\":\n",
        "                _dbg(f\"Qdrant[{collection}] empty → fallback RELAXED (giữ price).\")\n",
        "                cond_relaxed = build_filter(parent_uid=parent_uid, price_gte=price_gte, price_lte=price_lte)\n",
        "            else:\n",
        "                cond_relaxed = None\n",
        "            df = qdrant_search(client, collection, qv, _topk, cond_relaxed)\n",
        "            _dbg(f\"Qdrant[{collection}] relaxed: {len(df)}\")\n",
        "            if df.empty:\n",
        "                _dbg(f\"Qdrant[{collection}] still empty - NO-FILTER.\")\n",
        "                df = qdrant_search(client, collection, qv, _topk, flt=None)\n",
        "                _dbg(f\"Qdrant[{collection}] no-filter: {len(df)}\")\n",
        "\n",
        "        if collection == \"product_bge\":\n",
        "            if USE_RERANK and not df.empty:\n",
        "                _dbg(\"Apply soft rerank by rating/reviews on product.\")\n",
        "                df = _rerank(df)\n",
        "            df = dedup_product(df, per_parent=DEDUP_PER_PARENT)\n",
        "        elif collection == \"faq_bge\":\n",
        "            p_sig, f_sig_local = route_strength(query)\n",
        "            if not df.empty and f_sig_local > 0:\n",
        "                df[\"score\"] = df[\"score\"] * 1.07\n",
        "            df = dedup_faq(df)\n",
        "        return df\n",
        "\n",
        "    p_sig, f_sig = route_strength(query)\n",
        "    _dbg(f\"Route signals: product={p_sig}, faq={f_sig}\")\n",
        "\n",
        "    if target == \"faq\":\n",
        "        _dbg(\"Target=faq → query faq_bge only\")\n",
        "        df_faq = search_with_fallback(\"faq_bge\", cond_faq, topk)\n",
        "        _peek(df_faq, [\"title\", \"score\", \"url\"], title=\"Top FAQ\")\n",
        "        return \"faq\", df_faq\n",
        "\n",
        "    if target == \"both\" and f_sig >= p_sig + 1:\n",
        "        _dbg(\"Target=both nhưng FAQ mạnh hơn - trả FAQ\")\n",
        "        a = search_with_fallback(\"faq_bge\", cond_faq, topk)\n",
        "        _peek(a, [\"title\", \"score\", \"url\"], title=\"Top FAQ\")\n",
        "        return \"faq\", a\n",
        "\n",
        "    df_dense_chunks = search_with_fallback(\"product_bge\", cond_product, max(dense_topk_chunks, topk * 4))\n",
        "    _dbg(f\"Dense-chunk hits: {len(df_dense_chunks)}\")\n",
        "    _peek(df_dense_chunks, [\"parent_uid\", \"score\", \"title\", \"price\"], title=\"Dense-chunk (peek)\")\n",
        "\n",
        "    df_dense_parent = _aggregate_dense_by_parent(df_dense_chunks)[[\"parent_uid\", \"score_dense_parent\"]]\n",
        "    _dbg(f\"Dense→Parent rows: {len(df_dense_parent)}\")\n",
        "    _peek(df_dense_parent, [\"parent_uid\", \"score_dense_parent\"], title=\"Dense→Parent (peek)\")\n",
        "\n",
        "    if bm25_index is not None:\n",
        "        q_sparse = _norm_sparse_query(query)\n",
        "        df_sparse_parent = bm25_index.search(q_sparse, topk=bm25_topk_parents)\n",
        "        df_sparse_parent = df_sparse_parent.rename(columns={\"score\": \"score\"})[[\"parent_uid\", \"score\"]]\n",
        "        _dbg(f\"BM25-parent hits: {len(df_sparse_parent)}\")\n",
        "        _peek(df_sparse_parent, [\"parent_uid\", \"score\"], title=\"BM25-parent (peek)\")\n",
        "    else:\n",
        "        df_sparse_parent = pd.DataFrame(columns=[\"parent_uid\", \"score\"])\n",
        "        _dbg(\"BM25 index is None → skip sparse stage.\")\n",
        "\n",
        "    fused_parents = _fuse_parent_rrf(\n",
        "        df_dense_parent=df_dense_parent,\n",
        "        df_sparse_parent=df_sparse_parent,\n",
        "        parent_lookup_rev=parent_lookup_rev,\n",
        "        topk=max(topk * 3, 12),\n",
        "        k=rrf_k,\n",
        "        lam=rrf_lambda\n",
        "    )\n",
        "    _dbg(f\"Fused parents: {len(fused_parents)}\")\n",
        "    _peek(fused_parents, [\"parent_uid\", \"_rrf\", \"rank\", \"_pid_key\"], title=\"Fused-parent (peek)\")\n",
        "\n",
        "    out_chunks = []\n",
        "    have = set()\n",
        "    if not df_dense_chunks.empty:\n",
        "        pool = (\n",
        "            df_dense_chunks.sort_values([\"parent_uid\", \"score\"], ascending=[True, False])\n",
        "            .groupby(\"parent_uid\")\n",
        "            .head(per_parent_chunks)\n",
        "        )\n",
        "        out_chunks.append(pool)\n",
        "        have = set(pool[\"parent_uid\"].unique().tolist())\n",
        "\n",
        "    need_fetch_keys = []\n",
        "    for _, row in fused_parents.iterrows():\n",
        "        pu = row[\"parent_uid\"]\n",
        "        if pu not in have:\n",
        "            need_fetch_keys.append(row[\"_pid_key\"])\n",
        "\n",
        "    _dbg(f\"Need fetch by parent (from sparse-fused): {len(need_fetch_keys)}\")\n",
        "    for key in need_fetch_keys:\n",
        "        mapped = parent_lookup.get(str(key), \"\")\n",
        "        if not mapped:\n",
        "            _dbg(f\"   skip key={key}, no mapping in parent_lookup\")\n",
        "            continue\n",
        "        fetched = _fetch_best_chunks_for_parent(\n",
        "            client, qv, mapped, take=per_parent_chunks,\n",
        "            price_gte=price_gte, price_lte=price_lte\n",
        "        )\n",
        "        _dbg(f\"   fetch key={key} - mapped={mapped}: {len(fetched)} chunk\")\n",
        "        if not fetched.empty:\n",
        "            out_chunks.append(fetched)\n",
        "\n",
        "    out_chunks = [df for df in out_chunks if df is not None and not df.empty]\n",
        "    if out_chunks:\n",
        "        prod = pd.concat(out_chunks, ignore_index=True)\n",
        "        top_parent_keys = fused_parents[\"_pid_key\"].astype(str).tolist()\n",
        "        order_map = {k: i for i, k in enumerate(top_parent_keys)}\n",
        "\n",
        "        def _prod_pid_key(pid: str) -> str:\n",
        "            return _parent_key_for_dense(pid, parent_lookup_rev)\n",
        "\n",
        "        prod[\"_pid_key\"] = prod[\"parent_uid\"].map(_prod_pid_key).astype(str)\n",
        "        prod[\"_ord\"] = prod[\"_pid_key\"].map(order_map).fillna(1e9)\n",
        "        prod = prod.sort_values([\"_ord\", \"score\"], ascending=[True, False]).drop(columns=[\"_ord\"])\n",
        "        prod = prod.groupby(\"parent_uid\", as_index=False, sort=False).head(per_parent_chunks)\n",
        "        prod = prod.head(topk).reset_index(drop=True)\n",
        "    else:\n",
        "        DEF_COLS_LOCAL = [\"parent_uid\", \"score\", \"title\", \"price\", \"url\"]\n",
        "        prod = pd.DataFrame(columns=DEF_COLS_LOCAL)\n",
        "\n",
        "    _dbg(f\"Product chunks before score-merge: {len(prod)}\")\n",
        "    _peek(prod, [\"parent_uid\", \"score\", \"title\", \"price\"], title=\"Product (pre-merge, peek)\")\n",
        "\n",
        "    if not fused_parents.empty and not prod.empty:\n",
        "        parent_rrf = dict(zip(fused_parents[\"_pid_key\"].astype(str), fused_parents[\"_rrf\"]))\n",
        "        prod[\"_rrf_parent\"] = prod[\"_pid_key\"].map(parent_rrf).fillna(0.0)\n",
        "\n",
        "        alpha = 0.8\n",
        "        if RE_TECH_UNITS.search(query) or re.search(r'\\b[A-Z0-9]{3,}[-_\\.]?[A-Z0-9]{2,}\\b', query, re.I):\n",
        "            alpha = 0.65\n",
        "\n",
        "        prod[\"score_dense_tmp\"] = pd.to_numeric(prod[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "        prod[\"score\"] = alpha * prod[\"score_dense_tmp\"] + (1.0 - alpha) * pd.to_numeric(prod[\"_rrf_parent\"], errors=\"coerce\").fillna(0.0)\n",
        "        prod = prod.drop(columns=[\"_rrf_parent\", \"score_dense_tmp\", \"_pid_key\"])\n",
        "        _dbg(f\"Merged chunk score = {alpha:.2f}*dense + {(1.0-alpha):.2f}*rrf_parent\")\n",
        "\n",
        "    if prod.empty and (bm25_index is not None):\n",
        "        _dbg(\"Product empty → BM25-only rescue.\")\n",
        "        q_sparse = _norm_sparse_query(query)\n",
        "        df_sparse_parent_full = bm25_index.search(q_sparse, topk=max(topk * 6, 60))\n",
        "        _dbg(f\"   BM25 rescue parents: {len(df_sparse_parent_full)}\")\n",
        "        out = []\n",
        "        for pid in df_sparse_parent_full[\"parent_uid\"].head(topk * 3):\n",
        "            mapped = normalize_parent_for_qdrant(pid, parent_lookup)\n",
        "            fetched = _fetch_best_chunks_for_parent(\n",
        "                client, qv, mapped, take=per_parent_chunks,\n",
        "                price_gte=price_gte, price_lte=price_lte\n",
        "            )\n",
        "            _dbg(f\"   rescue fetch parent={pid} - mapped={mapped}: {len(fetched)} chunk\")\n",
        "            if not fetched.empty:\n",
        "                out.append(fetched)\n",
        "        if out:\n",
        "            prod = (\n",
        "                pd.concat(out, ignore_index=True)\n",
        "                .groupby(\"parent_uid\", as_index=False, sort=False)\n",
        "                .head(per_parent_chunks)\n",
        "                .head(topk)\n",
        "                .reset_index(drop=True)\n",
        "            )\n",
        "            _dbg(f\"   rescue produced: {len(prod)}\")\n",
        "\n",
        "    if prod.empty and not df_dense_chunks.empty:\n",
        "        _dbg(\"Product still empty - fallback to dense-topK chunks.\")\n",
        "        prod = (\n",
        "            df_dense_chunks\n",
        "            .sort_values(\"score\", ascending=False)\n",
        "            .groupby(\"parent_uid\", as_index=False, sort=False)\n",
        "            .head(per_parent_chunks)\n",
        "            .head(topk)\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "    if not prod.empty and (price_gte is not None or price_lte is not None):\n",
        "        before = len(prod)\n",
        "        if price_gte is not None:\n",
        "            prod = prod[pd.to_numeric(prod[\"price\"], errors=\"coerce\").fillna(np.inf) >= float(price_gte)]\n",
        "        if price_lte is not None:\n",
        "            prod = prod[pd.to_numeric(prod[\"price\"], errors=\"coerce\").fillna(-np.inf) <= float(price_lte)]\n",
        "        prod = prod.reset_index(drop=True)\n",
        "        _dbg(f\"Enforce price filter: {before} → {len(prod)}\")\n",
        "\n",
        "    _dbg(f\"Final product rows: {len(prod)}\")\n",
        "    _peek(prod, [\"parent_uid\", \"score\", \"title\", \"price\", \"url\"], title=\"Product (final, peek)\")\n",
        "\n",
        "    if target == \"product\":\n",
        "        _dbg(\"Return PRODUCT only.\")\n",
        "        return \"product\", prod\n",
        "\n",
        "    _dbg(\"Route BOTH → also fetch FAQ.\")\n",
        "    a = search_with_fallback(\"faq_bge\", cond_faq, topk)\n",
        "    _peek(a, [\"title\", \"score\", \"url\"], title=\"FAQ (peek)\")\n",
        "    merged = pd.concat([a, prod], ignore_index=True) if not a.empty else prod.copy()\n",
        "    merged = dedup_merged(merged)\n",
        "    merged = merged.sort_values(\"score\", ascending=False).head(topk).reset_index(drop=True)\n",
        "    _dbg(f\"Final BOTH rows: {len(merged)}\")\n",
        "    _peek(merged, [\"type\", \"score\", \"title\", \"price\", \"url\"], title=\"BOTH (final, peek)\")\n",
        "    return \"both\", merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGPO-l4AGv_g"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class LLMConfig:\n",
        "    model_name: str = \"Qwen2.5-7B-Instruct\"\n",
        "    load_in_4bit: bool = True\n",
        "    quant_type: str = \"nf4\"\n",
        "    compute_dtype = torch.bfloat16\n",
        "    double_quant: bool = True\n",
        "    device_map: str = \"auto\"\n",
        "    max_new_tokens: int = 512\n",
        "    temperature: float = 0.2\n",
        "    top_p: float = 0.9\n",
        "    repetition_penalty: float = 1.05\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LLMWrapper:\n",
        "    tokenizer: AutoTokenizer\n",
        "    model: AutoModelForCausalLM\n",
        "    cfg: LLMConfig\n",
        "\n",
        "\n",
        "def load_llm(cfg: Optional[LLMConfig] = None) -> LLMWrapper:\n",
        "    cfg = cfg or LLMConfig()\n",
        "    if cfg.load_in_4bit:\n",
        "        bnb = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=cfg.quant_type,\n",
        "            bnb_4bit_compute_dtype=cfg.compute_dtype,\n",
        "            bnb_4bit_use_double_quant=cfg.double_quant,\n",
        "        )\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            cfg.model_name,\n",
        "            quantization_config=bnb,\n",
        "            device_map=cfg.device_map,\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            cfg.model_name,\n",
        "            torch_dtype=cfg.compute_dtype,\n",
        "            device_map=cfg.device_map,\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "    tok = AutoTokenizer.from_pretrained(cfg.model_name)\n",
        "    if tok.pad_token_id is None and tok.eos_token_id is not None:\n",
        "        tok.pad_token_id = tok.eos_token_id\n",
        "    return LLMWrapper(tokenizer=tok, model=model, cfg=cfg)\n",
        "\n",
        "\n",
        "def _safe(x, default=\"\"):\n",
        "    return default if x is None else str(x)\n",
        "\n",
        "\n",
        "def pick_topk_parents(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
        "    if df is None or df.empty:\n",
        "        return df\n",
        "    base = df.sort_values([\"score\"], ascending=False)\n",
        "    return (\n",
        "        base.groupby(\"parent_uid\", as_index=False, sort=False)\n",
        "        .head(1)\n",
        "        .head(k)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def format_context_for_llm_product_browse(df: pd.DataFrame, max_items: int = 5) -> str:\n",
        "    if df is None or df.empty:\n",
        "        return \"\"\n",
        "    rows = []\n",
        "    for i, row in df.head(max_items).iterrows():\n",
        "        title = _safe(row.get(\"title\")).strip()\n",
        "        price = _safe(row.get(\"price\", \"\"))\n",
        "        url = _safe(row.get(\"url\", \"\")).strip()\n",
        "        rows.append(\n",
        "            f\"[{i+1}]\\n\"\n",
        "            f\"Tên: {title}\\n\"\n",
        "            f\"Giá_raw: {price}\\n\"\n",
        "            f\"Link: {url}\\n\"\n",
        "        )\n",
        "    return \"\\n\".join(rows)\n",
        "\n",
        "\n",
        "def format_context_for_llm_product_detail(df: pd.DataFrame) -> str:\n",
        "    if df is None or df.empty:\n",
        "        return \"\"\n",
        "    rows = []\n",
        "    for i, row in df.iterrows():\n",
        "        raw_text = _safe(row.get(\"text\", \"\"))\n",
        "        snippet = _clean_snippet_for_llm(raw_text)[:900]\n",
        "        rows.append(\n",
        "            f\"[{i+1}] {(_safe(row.get('title'))).strip()}\\n\"\n",
        "            f\"Giá_raw: {_safe(row.get('price',''))}\\n\"\n",
        "            f\"URL: {_safe(row.get('url',''))}\\n\"\n",
        "            f\"{snippet}\"\n",
        "        )\n",
        "    return \"\\n\".join(rows)\n",
        "\n",
        "\n",
        "def format_context_for_llm_faq(df: pd.DataFrame, max_items: int = 5) -> str:\n",
        "    if df is None or df.empty:\n",
        "        return \"\"\n",
        "    rows = []\n",
        "    for i, row in df.head(max_items).iterrows():\n",
        "        snippet = _safe(row.get(\"text\", \"\"))[:1200]\n",
        "        rows.append(\n",
        "            f\"[{i+1}] {(_safe(row.get('title'))).strip()} | \"\n",
        "            f\"URL: {_safe(row.get('url',''))}\\n{snippet}\"\n",
        "        )\n",
        "    return \"\\n\".join(rows)\n",
        "\n",
        "\n",
        "def build_prompt_product(query: str, context: str, no_result: bool = False, mode: str = \"browse\") -> List[Dict[str, str]]:\n",
        "    if mode != \"detail\":\n",
        "        sys = (\n",
        "            \"Bạn là trợ lý AI tư vấn sản phẩm trên Tiki.\\n\"\n",
        "            \"- Chỉ được sử dụng đúng dữ liệu được cung cấp trong phần 'Dữ liệu'.\\n\"\n",
        "            \"- Không bịa thêm thông tin.\\n\"\n",
        "            \"- Phải liệt kê ĐẦY ĐỦ các sản phẩm.\\n\"\n",
        "            \"- Trình bày dạng DANH SÁCH ĐÁNH SỐ (1., 2., 3...).\\n\"\n",
        "            \"- Không dùng chữ IN HOA toàn dòng.\\n\"\n",
        "            \"- Mỗi sản phẩm trình bày đúng 3 dòng: tên, giá, link.\"\n",
        "        )\n",
        "        if no_result:\n",
        "            user = (\n",
        "                f\"Câu hỏi: {query}\\n\\n\"\n",
        "                \"Dữ liệu: (không có sản phẩm phù hợp)\"\n",
        "            )\n",
        "        else:\n",
        "            user = (\n",
        "                f\"Câu hỏi: {query}\\n\\n\"\n",
        "                f\"Dữ liệu (mỗi sản phẩm có dạng):\\n\"\n",
        "                f\"{context}\\n\\n\"\n",
        "                \"Yêu cầu trả lời:\\n\"\n",
        "                \"1. Bắt đầu câu trả lời bằng dòng:\\n\"\n",
        "                \"   'Bạn có thể tham khảo các sản phẩm sau:'\\n\\n\"\n",
        "                \"2. Sau đó, với MỖI sản phẩm trong Dữ liệu, hãy in theo đúng mẫu:\\n\"\n",
        "                \"   1. <Tên sản phẩm>\\n\"\n",
        "                \"      Giá: <giá, dùng dấu CHẤM phân tách hàng nghìn, thêm ký hiệu '₫'>\\n\"\n",
        "                \"      Link: <Link>\\n\"\n",
        "                \"   2. ...\\n\"\n",
        "                \"   3. ...\\n\"\n",
        "                \"   (không được bỏ sót sản phẩm nào trong Dữ liệu)\\n\\n\"\n",
        "                \"   Ví dụ format:\\n\"\n",
        "                \"   1. Áo khoác nam XYZ\\n\"\n",
        "                \"      Giá: 156.450₫\\n\"\n",
        "                \"      Link: https://tiki.vn/...\\n\\n\"\n",
        "                \"3. Cuối cùng, thêm 1 dòng hỏi:\\n\"\n",
        "                \"   'Bạn có muốn mình gợi ý thêm hoặc lọc theo giá/thương hiệu không?'\\n\"\n",
        "            )\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": sys},\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "        ]\n",
        "\n",
        "\n",
        "def build_prompt_faq(query: str, context: str, no_result: bool = False) -> List[Dict[str, str]]:\n",
        "    sys = (\n",
        "        \"Bạn là trợ lý hỗ trợ Tiki.\\n\"\n",
        "        \"- CHỈ được sử dụng nội dung trong phần 'Dữ liệu'.\\n\"\n",
        "        \"- KHÔNG được thêm thông tin mới, ví dụ: địa chỉ kho, kênh đổi trả khác, \"\n",
        "        \"chính sách không có trong Dữ liệu.\\n\"\n",
        "        \"- KHÔNG được tự bịa ra link hay URL mới.\\n\"\n",
        "        \"- Nếu câu trả lời cần thông tin không có trong Dữ liệu, hãy trả lời: \"\n",
        "        \"'Không tìm thấy trong Dữ liệu, vui lòng xem thêm trên trang hỗ trợ Tiki hoặc liên hệ Tiki'.\"\n",
        "    )\n",
        "    if no_result:\n",
        "        user = (\n",
        "            f\"Câu hỏi: {query}\\n\\n\"\n",
        "            \"Dữ liệu: (không có kết quả phù hợp)\\n\\n\"\n",
        "            \"Hãy trả lời đúng theo hướng dẫn trong system. \"\n",
        "            \"Nếu không có dữ liệu, hãy nói rõ là không tìm thấy trong Dữ liệu.\"\n",
        "        )\n",
        "    else:\n",
        "        user = (\n",
        "            f\"Câu hỏi: {query}\\n\\n\"\n",
        "            f\"Dữ liệu:\\n{context}\\n\\n\"\n",
        "            \"Yêu cầu trả lời:\\n\"\n",
        "            \"- Chỉ được tóm tắt và trích ý từ Dữ liệu.\\n\"\n",
        "            \"- Không được bịa ra quy trình hay chính sách không có trong Dữ liệu.\\n\"\n",
        "            \"- Trả lời ngắn gọn, rõ ràng, có thể dùng gạch đầu dòng.\\n\"\n",
        "            \"- KHÔNG cần liệt kê link, hệ thống sẽ tự thêm link ở dưới câu trả lời.\"\n",
        "        )\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "\n",
        "def _clean_detail_answer(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Dọn rác câu trả lời mode DETAIL:\n",
        "    - Cắt bỏ phần LLM lặp lại 'CÂU HỎI', 'DỮ LIỆU', v.v.\n",
        "    - Cắt sớm các đoạn chém gió kiểu CSKH (Mọi ý kiến đóng góp..., Mọi thắc mắc khác...)\n",
        "    - Chỉnh format link xuống dòng sau 'tại đây:'.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    cleaned = text\n",
        "    cut_markers = [\n",
        "        \"CÂU HỎI\", \"Cau hoi\", \"Câu hỏi\",\n",
        "        \"DỮ LIỆU\", \"DỮ LIỆT\", \"Dữ liệu\",\n",
        "        \"\\n[1]\",\n",
        "        \"Mọi ý kiến đóng góp của quý khách\",\n",
        "        \"Mọi thông tin chi tiết về sản phẩm cũng như trải nghiệm mua sắm\",\n",
        "        \"Mọi thắc mắc khác, quý khách có thể liên hệ\",\n",
        "        \"Mọi thắc mắc khác vui lòng liên hệ\",\n",
        "        \"hotro@tiki.vn\",\n",
        "        \"1900-6035\",\n",
        "    ]\n",
        "    for m in cut_markers:\n",
        "        idx = cleaned.find(m)\n",
        "        if idx != -1:\n",
        "            cleaned = cleaned[:idx].strip()\n",
        "    cleaned = re.sub(\n",
        "        r\"(tại đây:)\\s*(https?://\\S+)\",\n",
        "        r\"\\1\\n\\2\",\n",
        "        cleaned,\n",
        "        flags=re.IGNORECASE,\n",
        "    )\n",
        "    return cleaned.strip()\n",
        "\n",
        "\n",
        "def generate_chat(\n",
        "    llm: LLMWrapper,\n",
        "    messages: List[Dict[str, str]],\n",
        "    max_new_tokens: Optional[int] = None,\n",
        "    temperature: Optional[float] = None,\n",
        "    top_p: Optional[float] = None,\n",
        ") -> str:\n",
        "    cfg = llm.cfg\n",
        "    max_new_tokens = max_new_tokens if max_new_tokens is not None else cfg.max_new_tokens\n",
        "    temperature = temperature if temperature is not None else 0.05\n",
        "    top_p = top_p if top_p is not None else 0.8\n",
        "    clean_messages = []\n",
        "    for m in messages or []:\n",
        "        if not m:\n",
        "            continue\n",
        "        role = m.get(\"role\", \"user\")\n",
        "        content = m.get(\"content\", \"\")\n",
        "        if content is None:\n",
        "            content = \"\"\n",
        "        clean_messages.append({\"role\": role, \"content\": str(content)})\n",
        "    if not clean_messages:\n",
        "        clean_messages = [{\"role\": \"user\", \"content\": \"\"}]\n",
        "    use_chat_template = True\n",
        "    try:\n",
        "        inputs = llm.tokenizer.apply_chat_template(\n",
        "            clean_messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(llm.model.device)\n",
        "        input_ids = inputs\n",
        "        prompt_len = input_ids.shape[1]\n",
        "    except Exception:\n",
        "        use_chat_template = False\n",
        "        prompt_parts = []\n",
        "        for m in clean_messages:\n",
        "            r = m[\"role\"]\n",
        "            c = m[\"content\"]\n",
        "            if r == \"system\":\n",
        "                prompt_parts.append(f\"[SYSTEM]\\n{c}\\n\")\n",
        "            elif r == \"user\":\n",
        "                prompt_parts.append(f\"[USER]\\n{c}\\n\")\n",
        "            elif r == \"assistant\":\n",
        "                prompt_parts.append(f\"[ASSISTANT]\\n{c}\\n\")\n",
        "            else:\n",
        "                prompt_parts.append(f\"[{r.upper()}]\\n{c}\\n\")\n",
        "        prompt = \"\\n\".join(prompt_parts) + \"\\n[ASSISTANT]\\n\"\n",
        "        enc = llm.tokenizer(prompt, return_tensors=\"pt\").to(llm.model.device)\n",
        "        input_ids = enc[\"input_ids\"]\n",
        "        prompt_len = input_ids.shape[1]\n",
        "    out = llm.model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=(temperature > 0),\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        repetition_penalty=cfg.repetition_penalty,\n",
        "        pad_token_id=llm.tokenizer.pad_token_id,\n",
        "        eos_token_id=llm.tokenizer.eos_token_id,\n",
        "    )\n",
        "    gen_ids = out[0, prompt_len:]\n",
        "    text = llm.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def expand_parents_with_more_chunks(\n",
        "    df_prod_one_chunk: pd.DataFrame,\n",
        "    client,\n",
        "    embed_query_fn,\n",
        "    query: str,\n",
        "    per_parent_chunks: int = 2,\n",
        "    price_gte: Optional[float] = None,\n",
        "    price_lte: Optional[float] = None,\n",
        ") -> pd.DataFrame:\n",
        "    if df_prod_one_chunk is None or df_prod_one_chunk.empty:\n",
        "        return df_prod_one_chunk\n",
        "    if per_parent_chunks <= 1:\n",
        "        return df_prod_one_chunk\n",
        "    qv = embed_query_fn(query)\n",
        "    parents = df_prod_one_chunk[\"parent_uid\"].dropna().unique().tolist()\n",
        "    take = max(2, per_parent_chunks)\n",
        "    rows = []\n",
        "    for pu in parents:\n",
        "        try:\n",
        "            flt = build_filter(\n",
        "                parent_uid=pu,\n",
        "                price_gte=price_gte,\n",
        "                price_lte=price_lte,\n",
        "            )\n",
        "            more = qdrant_search(client, \"product_bge\", qv, topk=take, flt=flt)\n",
        "            if more is not None and not more.empty:\n",
        "                rows.append(more)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not rows:\n",
        "        return df_prod_one_chunk\n",
        "    expanded = pd.concat([df_prod_one_chunk] + rows, ignore_index=True)\n",
        "    expanded = (\n",
        "        expanded.sort_values([\"parent_uid\", \"score\"], ascending=[True, False])\n",
        "        .groupby(\"parent_uid\", as_index=False, sort=False)\n",
        "        .head(per_parent_chunks)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    return expanded\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AnswerPolicy:\n",
        "    min_results_product: int = 1\n",
        "    min_results_faq: int = 1\n",
        "    min_score_product: float = 0.0\n",
        "    min_score_faq: float = 0.0\n",
        "    allow_expand_chunks_detail: bool = True\n",
        "    expand_chunks_per_parent_detail: int = 3\n",
        "    token_budget_est_product_browse: int = 900\n",
        "    token_budget_est_product_detail: int = 1000\n",
        "    token_budget_est_faq: int = 1500\n",
        "    per_item_char_budget_product_browse: int = 200\n",
        "    per_item_char_budget_product_detail: int = 700\n",
        "    per_item_char_budget_faq: int = 420\n",
        "\n",
        "\n",
        "def _should_no_result(df: pd.DataFrame, min_results: int, min_score: float) -> bool:\n",
        "    if df is None or df.empty:\n",
        "        return True\n",
        "    if len(df) < min_results:\n",
        "        return True\n",
        "    if min_score > 0.0 and \"score\" in df.columns:\n",
        "        tops = pd.to_numeric(df[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "        if float(tops.max()) < min_score:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def _trim_budget(df: pd.DataFrame, token_budget_est: int, per_item_char_budget: int) -> pd.DataFrame:\n",
        "    if df is None or df.empty:\n",
        "        return df\n",
        "    max_items = max(1, math.floor(token_budget_est / max(1, per_item_char_budget)))\n",
        "    return df.head(max_items).reset_index(drop=True)\n",
        "\n",
        "\n",
        "DETAIL_TERMS = [\n",
        "    \"thông số\", \"chi tiết\", \"cấu hình\", \"bao lâu\", \"giữ nóng\",\n",
        "    \"giữ lạnh\", \"dung tích\", \"kích thước\", \"bao nhiêu w\", \"bao nhiêu watt\",\n",
        "    \"bảo hành\", \"xuất xứ\", \"chống nước\", \"có tốt không\", \"hợp không\",\n",
        "]\n",
        "BROWSE_TERMS = [\n",
        "    \"loại nào\", \"nên mua\", \"gợi ý\", \"tư vấn\", \"tầm\", \"khoảng\",\n",
        "    \"dưới\", \"trên\", \"giữa\", \"so sánh\", \"top\", \"phù hợp\",\n",
        "]\n",
        "MODEL_PATTERN = re.compile(r\"\\b[A-Z0-9]{2,}[-_ ]?[A-Z0-9]{2,}\\b\")\n",
        "\n",
        "DETAIL_PATTERNS = [\n",
        "    r\"mấy\\s+sim\",\n",
        "    r\"may\\s+sim\",\n",
        "    r\"bao\\s+nhiêu\\s+sim\",\n",
        "    r\"bao\\s+nhiu\\s+sim\",\n",
        "    r\"esim\",\n",
        "    r\"e\\s*sim\",\n",
        "    r\"có\\s+chống\\s+nước\\s+không\",\n",
        "    r\"co\\s+chong\\s+nuoc\\s+khong\",\n",
        "    r\"có\\s+sạc\\s+nhanh\\s+không\",\n",
        "    r\"co\\s+sac\\s+nhanh\\s+khong\",\n",
        "    r\"bao\\s+nhiêu\\s+gb\",\n",
        "    r\"bao\\s+nhiu\\s+gb\",\n",
        "    r\"ram\\s+mấy\\s*gb\",\n",
        "    r\"rom\\s+mấy\\s*gb\",\n",
        "]\n",
        "\n",
        "INFO_DETAIL_RE = re.compile(\n",
        "    r\"thông\\s*tin\\s*(chi\\s*tiết\\s*)?(sản\\s*phẩm|ve)\\b\",\n",
        "    re.I\n",
        ")\n",
        "\n",
        "INFO_TERMS = [\n",
        "    \"thông tin\",\n",
        "    \"thong tin\",\n",
        "    \"giới thiệu\",\n",
        "    \"gioi thieu\",\n",
        "    \"review\",\n",
        "    \"đánh giá sản phẩm\",\n",
        "    \"danh gia san pham\",\n",
        "]\n",
        "\n",
        "\n",
        "def detect_product_mode(query: str, df_top: pd.DataFrame) -> str:\n",
        "    q_raw = unicodedata.normalize(\"NFKC\", query)\n",
        "    q = q_raw.lower()\n",
        "    try:\n",
        "        q_ascii = strip_accents(q_raw).lower()\n",
        "    except Exception:\n",
        "        q_ascii = q\n",
        "\n",
        "    def _has_any(term_list):\n",
        "        return any(t in q for t in term_list) or any(t in q_ascii for t in term_list)\n",
        "\n",
        "    for pat in DETAIL_PATTERNS:\n",
        "        if re.search(pat, q):\n",
        "            return \"detail\"\n",
        "    if _has_any(DETAIL_TERMS):\n",
        "        return \"detail\"\n",
        "    if _has_any(BROWSE_TERMS):\n",
        "        return \"browse\"\n",
        "    if MODEL_PATTERN.search(query):\n",
        "        return \"detail\"\n",
        "    if df_top is not None and not df_top.empty:\n",
        "        n_parent = df_top[\"parent_uid\"].nunique()\n",
        "        if n_parent == 1:\n",
        "            return \"detail\"\n",
        "        if _has_any(INFO_TERMS) and n_parent > 1:\n",
        "            return \"clarify\"\n",
        "    return \"browse\"\n",
        "\n",
        "\n",
        "def build_top1_faq_fullparent(\n",
        "    df_all: pd.DataFrame,\n",
        "    client,\n",
        "    query: str,\n",
        "    max_chunks_per_parent: int = 4,\n",
        ") -> pd.DataFrame:\n",
        "    if df_all is None or df_all.empty:\n",
        "        return pd.DataFrame()\n",
        "    if \"parent_uid\" not in df_all.columns:\n",
        "        return pd.DataFrame()\n",
        "    df_sorted = df_all.sort_values(\"score\", ascending=False)\n",
        "    top_row = df_sorted.iloc[0]\n",
        "    top_parent = top_row.get(\"parent_uid\")\n",
        "    if not top_parent:\n",
        "        return pd.DataFrame()\n",
        "    base = df_all[df_all[\"parent_uid\"] == top_parent].copy()\n",
        "    chunks_list = []\n",
        "    if base is not None and not base.empty:\n",
        "        chunks_list.append(base)\n",
        "    try:\n",
        "        qv = embed_query(query)\n",
        "        flt = build_filter(parent_uid=top_parent)\n",
        "        more = qdrant_search(\n",
        "            client,\n",
        "            collection=\"faq_bge\",\n",
        "            qv=qv,\n",
        "            topk=max_chunks_per_parent,\n",
        "            flt=flt,\n",
        "        )\n",
        "        if more is not None and not more.empty:\n",
        "            chunks_list.append(more)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if not chunks_list:\n",
        "        return pd.DataFrame()\n",
        "    merged = pd.concat(chunks_list, ignore_index=True)\n",
        "    if \"id\" in merged.columns:\n",
        "        merged = merged.drop_duplicates(subset=[\"id\", \"text\"])\n",
        "    else:\n",
        "        merged = merged.drop_duplicates(subset=[\"text\"])\n",
        "    if \"score\" in merged.columns:\n",
        "        merged[\"score\"] = pd.to_numeric(merged[\"score\"], errors=\"coerce\").fillna(0.0)\n",
        "        merged = merged.sort_values(\"score\", ascending=False)\n",
        "    merged = merged.head(max_chunks_per_parent).reset_index(drop=True)\n",
        "    if merged.empty:\n",
        "        return pd.DataFrame()\n",
        "    title = \"\"\n",
        "    if \"title\" in merged.columns:\n",
        "        non_empty_titles = merged[\"title\"].dropna().astype(str)\n",
        "        if not non_empty_titles.empty:\n",
        "            title = non_empty_titles.iloc[0].strip()\n",
        "    url = \"\"\n",
        "    if \"url\" in merged.columns:\n",
        "        non_empty_urls = merged[\"url\"].dropna().astype(str)\n",
        "        if not non_empty_urls.empty:\n",
        "            url = non_empty_urls.iloc[0].strip()\n",
        "    texts = [\n",
        "        str(t).strip()\n",
        "        for t in merged[\"text\"].fillna(\"\").tolist()\n",
        "        if str(t).strip()\n",
        "    ]\n",
        "    full_text = \"\\n\\n\".join(texts)\n",
        "    max_chars_full = 6000\n",
        "    if len(full_text) > max_chars_full:\n",
        "        full_text = full_text[:max_chars_full]\n",
        "    score = float(merged[\"score\"].max()) if \"score\" in merged.columns else 0.0\n",
        "    row = {\n",
        "        \"parent_uid\": top_parent,\n",
        "        \"title\": title,\n",
        "        \"url\": url,\n",
        "        \"text\": full_text,\n",
        "        \"score\": score,\n",
        "    }\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "\n",
        "def render_product_list(df_ctx: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Render danh sách sản phẩm dạng đánh số:\n",
        "    1. Tên\n",
        "       Giá: 123.000₫\n",
        "       Link: ...\n",
        "    (KHÔNG thêm câu mở đầu, KHÔNG thêm câu hỏi cuối)\n",
        "    \"\"\"\n",
        "    if df_ctx is None or df_ctx.empty:\n",
        "        return \"\"\n",
        "    lines = []\n",
        "    for i, row in df_ctx.reset_index(drop=True).iterrows():\n",
        "        title = _safe(row.get(\"title\")).strip()\n",
        "        price_val = pd.to_numeric(row.get(\"price\"), errors=\"coerce\")\n",
        "        if np.isnan(price_val):\n",
        "            price_str = \"Đang cập nhật\"\n",
        "        else:\n",
        "            price_str = f\"{int(price_val):,}\".replace(\",\", \".\") + \"₫\"\n",
        "        url = _safe(row.get(\"url\")).strip()\n",
        "        lines.append(\n",
        "            f\"{i+1}. {title}\\n\"\n",
        "            f\"   Giá: {price_str}\\n\"\n",
        "            f\"   Link: {url}\"\n",
        "        )\n",
        "    return \"\\n\\n\".join(lines)\n",
        "\n",
        "\n",
        "def paraphrase_intro(llm: LLMWrapper, query: str) -> str:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"Bạn là trợ lý viết câu mở đầu cho danh sách sản phẩm.\\n\"\n",
        "                \"YÊU CẦU:\\n\"\n",
        "                \"- Nếu người dùng viết sai chính tả, hãy sửa lại cho đúng.\\n\"\n",
        "                \"- Viết lại câu hỏi thành một câu mở đầu tự nhiên, lịch sự, đúng chính tả.\\n\"\n",
        "                \"- Format gợi ý: 'Dưới đây là một số ... mà bạn có thể tham khảo:'.\\n\"\n",
        "                \"- KHÔNG trả về danh sách, chỉ trả về 1 câu mở đầu.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Tạo câu mở đầu dựa trên câu hỏi của người dùng: '{query}'.\"\n",
        "        }\n",
        "    ]\n",
        "    text = generate_chat(\n",
        "        llm,\n",
        "        messages,\n",
        "        max_new_tokens=40,\n",
        "        temperature=0.2,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def generate_product_detail_answer(\n",
        "    llm: LLMWrapper,\n",
        "    query: str,\n",
        "    context: str,\n",
        "    max_new_tokens: int = 160,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Sinh câu trả lời CHI TIẾT cho 1 sản phẩm, giọng chatbot CSKH.\n",
        "    Không dùng chat_template để tránh Qwen chèn system mặc định.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"Bạn là trợ lý AI tư vấn CHI TIẾT cho MỘT sản phẩm cụ thể trên Tiki.\\n\"\n",
        "        \"- Chỉ được sử dụng nội dung trong khối DỮ LIỆU.\\n\"\n",
        "        \"- Không được bịa thêm thông tin mới.\\n\"\n",
        "        \"- Nếu không đủ dữ liệu để trả lời chính xác, hãy trả lời đúng câu: \"\n",
        "        \"'không tìm thấy thông tin đủ chi tiết'.\\n\"\n",
        "        \"- KHÔNG được dùng format hội thoại như 'Human:', 'Assistant:', 'User:', 'Bot:'. \"\n",
        "        \"Chỉ trả lời trực tiếp cho khách.\\n\"\n",
        "        \"- Tập trung trả lời đúng nội dung câu hỏi, chỉ nhắc đến giá nếu khách hỏi về giá.\\n\\n\"\n",
        "        f\"CÂU HỎI CỦA KHÁCH: {query}\\n\\n\"\n",
        "        f\"DỮ LIỆU SẢN PHẨM:\\n{context}\\n\\n\"\n",
        "        \"YÊU CẦU TRẢ LỜI:\\n\"\n",
        "        \"- Trả lời trực tiếp câu hỏi của khách.\\n\"\n",
        "        \"- Dùng giọng tự nhiên, lịch sự, giống nhân viên CSKH trả lời.\\n\"\n",
        "        \"- Không cần nhắc lại nguyên văn dữ liệu, hãy diễn đạt lại cho dễ hiểu.\\n\"\n",
        "        \"- Có thể dùng 1–3 câu, hoặc 1–2 gạch đầu dòng nếu phù hợp.\\n\"\n",
        "        \"- KHÔNG chèn thêm ví dụ, không giới thiệu lan man.\\n\\n\"\n",
        "        \"TRẢ LỜI:\"\n",
        "    )\n",
        "    enc = llm.tokenizer(prompt, return_tensors=\"pt\").to(llm.model.device)\n",
        "    out = llm.model.generate(\n",
        "        **enc,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        top_p=1.0,\n",
        "        repetition_penalty=llm.cfg.repetition_penalty,\n",
        "        pad_token_id=llm.tokenizer.pad_token_id,\n",
        "        eos_token_id=llm.tokenizer.eos_token_id,\n",
        "    )\n",
        "    input_len = enc[\"input_ids\"].shape[1]\n",
        "    gen_ids = out[0, input_len:]\n",
        "    text = llm.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def generate_product_detail_noinfo_answer(\n",
        "    llm: LLMWrapper,\n",
        "    query: str,\n",
        "    product_title: str = \"\",\n",
        "    product_url: str = \"\",\n",
        "    max_new_tokens: int = 160,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Trường hợp KHÔNG tìm thấy fact phù hợp trong context:\n",
        "    - Không được bịa thông số.\n",
        "    - Được phép nói lịch sự rằng dữ liệu không có.\n",
        "    \"\"\"\n",
        "    extra = \"\"\n",
        "    if product_title:\n",
        "        extra += f\"- Tên sản phẩm: {product_title}\\n\"\n",
        "    if product_url:\n",
        "        extra += f\"- Link sản phẩm: {product_url}\\n\"\n",
        "    prompt = (\n",
        "        \"Bạn là trợ lý CSKH của Tiki.\\n\"\n",
        "        \"HỆ THỐNG THÔNG BÁO: Dữ liệu hiện tại KHÔNG chứa thông tin để trả lời CHÍNH XÁC câu hỏi của khách.\\n\"\n",
        "        \"YÊU CẦU RẤT QUAN TRỌNG:\\n\"\n",
        "        \"- KHÔNG được đoán.\\n\"\n",
        "        \"- KHÔNG được nêu bất kỳ con số hoặc thông số kỹ thuật cụ thể nào \"\n",
        "        \"(ví dụ: số SIM, dung lượng RAM, công suất W, chuẩn chống nước IPxx, v.v.).\\n\"\n",
        "        \"- Chỉ được nói rằng dữ liệu không có thông tin này, và đề xuất khách xem thêm trang sản phẩm \"\n",
        "        \"hoặc liên hệ CSKH để được tư vấn thêm.\\n\"\n",
        "        \"- Được phép diễn đạt lại nội dung trên theo cách lịch sự, tự nhiên (2–3 câu).\\n\"\n",
        "        \"- KHÔNG lặp đi lặp lại các câu rỗng như 'Mọi ý kiến đóng góp... đều quý giá...' \\n\\n\"\n",
        "        f\"CÂU HỎI CỦA KHÁCH: {query}\\n\\n\"\n",
        "        f\"THÔNG TIN BỔ SUNG (nếu có):\\n{extra}\\n\"\n",
        "        \"TRẢ LỜI:\"\n",
        "    )\n",
        "    enc = llm.tokenizer(prompt, return_tensors=\"pt\").to(llm.model.device)\n",
        "    out = llm.model.generate(\n",
        "        **enc,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        top_p=1.0,\n",
        "        repetition_penalty=llm.cfg.repetition_penalty,\n",
        "        pad_token_id=llm.tokenizer.pad_token_id,\n",
        "        eos_token_id=llm.tokenizer.eos_token_id,\n",
        "    )\n",
        "    input_len = enc[\"input_ids\"].shape[1]\n",
        "    gen_ids = out[0, input_len:]\n",
        "    text = llm.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def extract_main_title_url(df_ctx: pd.DataFrame) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Lấy title + url đại diện từ df_ctx (thường là dòng đầu tiên).\n",
        "    \"\"\"\n",
        "    if df_ctx is None or df_ctx.empty:\n",
        "        return \"\", \"\"\n",
        "    title = \"\"\n",
        "    url = \"\"\n",
        "    if \"title\" in df_ctx.columns:\n",
        "        t = df_ctx[\"title\"].dropna().astype(str)\n",
        "        if not t.empty:\n",
        "            title = t.iloc[0].strip()\n",
        "    if \"url\" in df_ctx.columns:\n",
        "        u = df_ctx[\"url\"].dropna().astype(str)\n",
        "        if not u.empty:\n",
        "            url = u.iloc[0].strip()\n",
        "    return title, url\n",
        "\n",
        "\n",
        "def _clean_snippet_for_llm(snippet: str) -> str:\n",
        "    \"\"\"\n",
        "    Loại bỏ các dòng dạng hội thoại demo: Human:, Assistant:, User:, Bot: ...\n",
        "    để tránh LLM bắt chước format đó.\n",
        "    \"\"\"\n",
        "    if not snippet:\n",
        "        return \"\"\n",
        "    lines = []\n",
        "    for line in str(snippet).splitlines():\n",
        "        l = line.strip().lower()\n",
        "        if l.startswith((\"human:\", \"assistant:\", \"user:\", \"bot:\")):\n",
        "            continue\n",
        "        lines.append(line)\n",
        "    cleaned = \"\\n\".join(lines).strip()\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def has_fact_for_query(query: str, context: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check xem trong context có 'dấu hiệu' của thông tin mà user hỏi không.\n",
        "    Mới xử lý kỹ cho mấy nhóm:\n",
        "      - số sim / eSIM\n",
        "      - chống nước\n",
        "      - công suất (W)\n",
        "      - RAM / ROM / GB\n",
        "    Các loại câu khác mặc định trả True (cho LLM trả lời bình thường).\n",
        "    \"\"\"\n",
        "    if not query or not context:\n",
        "        return False\n",
        "    q = unicodedata.normalize(\"NFKC\", query).lower()\n",
        "    ctx = unicodedata.normalize(\"NFKC\", context).lower()\n",
        "    if re.search(r\"(mấy\\s+sim|may\\s+sim|bao\\s+nhiêu\\s+sim|bao\\s+nhiu\\s+sim|esim|e\\s*sim)\", q):\n",
        "        return any(\n",
        "            kw in ctx\n",
        "            for kw in [\"số sim\", \"so sim\", \"loại sim\", \"loai sim\", \"sim:\", \"sim \", \"esim\", \"e sim\"]\n",
        "        )\n",
        "    if re.search(r\"(chống\\s*nước|chong\\s*nuoc|kháng\\s*nước|khang\\s*nuoc|ip[0-9]{2})\", q):\n",
        "        return any(\n",
        "            kw in ctx\n",
        "            for kw in [\"chống nước\", \"chong nuoc\", \"kháng nước\", \"khang nuoc\", \"chống thấm\", \"chong tham\", \"ip67\", \"ip68\"]\n",
        "        )\n",
        "    if re.search(r\"(công\\s*suất|cong\\s*suat|bao\\s+nhiêu\\s*w\\b|bao\\s+nhiu\\s*w\\b|watt?)\", q):\n",
        "        return any(\n",
        "            kw in ctx\n",
        "            for kw in [\"công suất\", \"cong suat\", \"watt\", \" w\", \"w \"]\n",
        "        )\n",
        "    if re.search(r\"(ram|rom|bộ\\s*nhớ|bo\\s*nho|gb\\b)\", q):\n",
        "        return any(\n",
        "            kw in ctx\n",
        "            for kw in [\"ram\", \"rom\", \"bộ nhớ\", \"bo nho\", \"gb\"]\n",
        "        )\n",
        "    return True\n",
        "\n",
        "\n",
        "def answer_with_rag(\n",
        "    llm: LLMWrapper,\n",
        "    client,\n",
        "    bm25_index,\n",
        "    query: str,\n",
        "    search_fn,\n",
        "    parent_lookup: Dict[str, str],\n",
        "    parent_lookup_rev: Dict[str, str],\n",
        "    policy: Optional[AnswerPolicy] = None,\n",
        "    topk: int = 5,\n",
        "    rrf_lambda: float = 0.8,\n",
        "    per_parent_chunks: int = 1,\n",
        "    verbose: bool = False,\n",
        ") -> Tuple[str, pd.DataFrame, str]:\n",
        "    policy = policy or AnswerPolicy()\n",
        "    target_raw, df_all = search_fn(\n",
        "        client,\n",
        "        bm25_index,\n",
        "        query=query,\n",
        "        topk=topk,\n",
        "        rrf_lambda=rrf_lambda,\n",
        "        per_parent_chunks=per_parent_chunks,\n",
        "        verbose=verbose,\n",
        "        parent_lookup=parent_lookup,\n",
        "        parent_lookup_rev=parent_lookup_rev\n",
        "    )\n",
        "    if df_all is None:\n",
        "        df_all = pd.DataFrame()\n",
        "    if verbose:\n",
        "        print(\"df_all shape:\", df_all.shape)\n",
        "        if \"type\" in df_all.columns:\n",
        "            print(\"type value_counts:\")\n",
        "            print(df_all[\"type\"].value_counts(dropna=False))\n",
        "        if \"parent_uid\" in df_all.columns:\n",
        "            print(\"unique parent_uid in df_all:\", df_all[\"parent_uid\"].nunique())\n",
        "    type_col = df_all[\"type\"].fillna(\"\").str.lower() if \"type\" in df_all.columns else \"\"\n",
        "    df_faq = df_all[type_col == \"faq\"].reset_index(drop=True)\n",
        "    df_prod = df_all[type_col != \"faq\"].reset_index(drop=True)\n",
        "    if verbose:\n",
        "        print(\"FAQ rows:\", len(df_faq), \"| PRODUCT rows:\", len(df_prod))\n",
        "\n",
        "    def _max(df):\n",
        "        if df is None or df.empty or \"score\" not in df.columns:\n",
        "            return -999\n",
        "        return float(pd.to_numeric(df[\"score\"], errors=\"coerce\").fillna(0).max())\n",
        "\n",
        "    faq_max = _max(df_faq)\n",
        "    prod_max = _max(df_prod)\n",
        "    if faq_max >= prod_max:\n",
        "        effective_target = \"faq\"\n",
        "    else:\n",
        "        effective_target = \"product\"\n",
        "    if verbose:\n",
        "        print(f\"target_raw={target_raw} → effective_target={effective_target}\")\n",
        "        print(f\"   max FAQ={faq_max}, max PRODUCT={prod_max}\")\n",
        "    if effective_target == \"faq\":\n",
        "        if df_faq.empty:\n",
        "            if verbose:\n",
        "                print(\"df_faq empty → no_result FAQ\")\n",
        "            messages = build_prompt_faq(query, context=\"\", no_result=True)\n",
        "            answer = generate_chat(llm, messages)\n",
        "            return \"faq\", df_all, answer\n",
        "        df_ctx = build_top1_faq_fullparent(\n",
        "            df_all=df_faq,\n",
        "            client=client,\n",
        "            query=query,\n",
        "            max_chunks_per_parent=8\n",
        "        )\n",
        "        if verbose:\n",
        "            print(\"df_ctx (FAQ full parent) shape:\", df_ctx.shape)\n",
        "            if not df_ctx.empty:\n",
        "                print(\"df_ctx FAQ row[0] text[:200]:\")\n",
        "                print(str(df_ctx.iloc[0].get(\"text\", \"\"))[:200])\n",
        "        none_found = _should_no_result(\n",
        "            df_ctx,\n",
        "            policy.min_results_faq,\n",
        "            policy.min_score_faq\n",
        "        )\n",
        "        if none_found or df_ctx is None or df_ctx.empty:\n",
        "            if verbose:\n",
        "                print(\"none_found / df_ctx empty → no_result FAQ\")\n",
        "            messages = build_prompt_faq(query, context=\"\", no_result=True)\n",
        "            answer = generate_chat(llm, messages)\n",
        "            return \"faq\", df_all, answer\n",
        "        ctx = format_context_for_llm_faq(df_ctx, max_items=len(df_ctx))\n",
        "        if verbose:\n",
        "            print(\"FAQ context length (chars):\", len(ctx))\n",
        "        messages = build_prompt_faq(query, ctx, no_result=False)\n",
        "        answer = generate_chat(llm, messages)\n",
        "        main_url = \"\"\n",
        "        if \"url\" in df_ctx.columns:\n",
        "            urls = df_ctx[\"url\"].dropna().astype(str)\n",
        "            if not urls.empty:\n",
        "                main_url = urls.iloc[0].strip()\n",
        "        if main_url:\n",
        "            answer = answer.rstrip() + f\"\\n\\nXem chi tiết tại: {main_url}\"\n",
        "        return \"faq\", df_ctx, answer\n",
        "\n",
        "    if df_prod.empty:\n",
        "        if verbose:\n",
        "            print(\"df_prod empty → no_result PRODUCT (browse prompt)\")\n",
        "        messages = build_prompt_product(query, context=\"\", no_result=True, mode=\"browse\")\n",
        "        answer = generate_chat(llm, messages)\n",
        "        return \"product\", df_all, answer\n",
        "    df_top = pick_topk_parents(df_prod, k=topk)\n",
        "    if verbose:\n",
        "        print(\"df_top (product) shape:\", df_top.shape)\n",
        "        if \"parent_uid\" in df_top.columns:\n",
        "            print(\"   unique parents in df_top:\", df_top[\"parent_uid\"].nunique())\n",
        "    mode = detect_product_mode(query, df_top)\n",
        "    if verbose:\n",
        "        print(f\"Product mode(final) = {mode}\")\n",
        "    if mode == \"clarify\":\n",
        "        df_ctx = df_top.head(3)\n",
        "        list_text = render_product_list(df_ctx)\n",
        "        intro = (\n",
        "            \"Mình thấy bạn đang muốn tìm thông tin sản phẩm nhưng hiện có nhiều mẫu phù hợp, \"\n",
        "            \"bạn muốn xem chi tiết của sản phẩm nào trong danh sách dưới đây ạ?\\n\\n\"\n",
        "        )\n",
        "        answer = (\n",
        "            intro +\n",
        "            f\"{list_text}\\n\\n\"\n",
        "            \"Bạn hãy gửi lại đúng tên sản phẩm để mình mô tả chi tiết nhé!\"\n",
        "        )\n",
        "        target = effective_target\n",
        "        return target, df_ctx, answer\n",
        "    if mode == \"browse\":\n",
        "        none_found = _should_no_result(\n",
        "            df_top,\n",
        "            policy.min_results_product,\n",
        "            policy.min_score_product,\n",
        "        )\n",
        "        if none_found or df_top is None or df_top.empty:\n",
        "            if verbose:\n",
        "                print(\"none_found → no_result PRODUCT (browse)\")\n",
        "            answer = (\n",
        "                f\"Hiện tại mình chưa tìm được sản phẩm phù hợp với yêu cầu: \\\"{query}\\\".\\n\"\n",
        "                \"Bạn có thể thử:\\n\"\n",
        "                \"- Đổi từ khóa tìm kiếm (ví dụ: rút gọn tên, bỏ bớt chữ 'pro', 'gen 2', ...)\\n\"\n",
        "                \"- Nới rộng khoảng giá hoặc bỏ bớt điều kiện lọc.\\n\\n\"\n",
        "                \"Nếu bạn muốn, mình có thể gợi ý từ khóa khác giúp bạn thử tìm lại.\"\n",
        "            )\n",
        "            target = effective_target\n",
        "            return target, df_all, answer\n",
        "        df_ctx = _trim_budget(\n",
        "            df_top,\n",
        "            policy.token_budget_est_product_browse,\n",
        "            policy.per_item_char_budget_product_browse,\n",
        "        )\n",
        "        if verbose:\n",
        "            print(\"df_ctx (product browse) shape:\", df_ctx.shape)\n",
        "        intro = paraphrase_intro(llm, query)\n",
        "        list_text = render_product_list(df_ctx)\n",
        "        followup = \"Bạn muốn xem chi tiết sản phẩm nào không?\"\n",
        "        answer = f\"{intro}\\n\\n{list_text}\\n\\n{followup}\"\n",
        "        target = effective_target\n",
        "        return target, df_ctx, answer\n",
        "        df_ctx = _trim_budget(\n",
        "            df_top,\n",
        "            policy.token_budget_est_product_browse,\n",
        "            policy.per_item_char_budget_product_browse,\n",
        "        )\n",
        "        intro = paraphrase_intro(llm, query)\n",
        "        q_clean = query.strip()\n",
        "        if q_clean and q_clean in intro:\n",
        "            intro = \"Dưới đây là một số sản phẩm phù hợp với yêu cầu của bạn:\"\n",
        "        list_text = render_product_list(df_ctx)\n",
        "        followup = \"Bạn muốn xem chi tiết sản phẩm nào không?\"\n",
        "        answer = f\"{intro}\\n\\n{list_text}\\n\\n{followup}\"\n",
        "        target = effective_target\n",
        "        return target, df_ctx, answer\n",
        "    if df_top is None or df_top.empty:\n",
        "        if verbose:\n",
        "            print(\"df_top empty in DETAIL mode → fallback message\")\n",
        "        answer = (\n",
        "            \"Trong dữ liệu hiện tại mình chưa tìm được sản phẩm nào đủ phù hợp để trả lời chi tiết cho câu hỏi này. \"\n",
        "            \"Bạn có thể mô tả rõ hơn tên sản phẩm (model/mã máy) hoặc thử từ khóa khác giúp mình nhé.\"\n",
        "        )\n",
        "        target = effective_target\n",
        "        return target, df_all, answer\n",
        "    main_row = df_top.sort_values(\"score\", ascending=False).iloc[0]\n",
        "    main_parent = main_row.get(\"parent_uid\")\n",
        "    if verbose:\n",
        "        print(\"main PRODUCT parent_uid:\", main_parent)\n",
        "    df_detail_base = df_all[df_all[\"parent_uid\"] == main_parent].copy()\n",
        "    if df_detail_base.empty:\n",
        "        df_detail_base = df_top[df_top[\"parent_uid\"] == main_parent].copy()\n",
        "    if verbose:\n",
        "        print(\"df_detail_base shape:\", df_detail_base.shape)\n",
        "    none_found = _should_no_result(\n",
        "        df_detail_base,\n",
        "        policy.min_results_product,\n",
        "        policy.min_score_product,\n",
        "    )\n",
        "    if none_found or df_detail_base.empty:\n",
        "        if verbose:\n",
        "            print(\"none_found in df_detail_base → fallback detail message\")\n",
        "        answer = (\n",
        "            \"Trong thông tin sản phẩm mà hệ thống đang có hiện tại \"\n",
        "            \"không đủ dữ liệu để trả lời chính xác câu hỏi này. \"\n",
        "            \"Bạn có thể kiểm tra thêm trực tiếp trên trang sản phẩm để chắc chắn hơn.\"\n",
        "        )\n",
        "        target = effective_target\n",
        "        return target, df_all, answer\n",
        "    if policy.allow_expand_chunks_detail and policy.expand_chunks_per_parent_detail > 1:\n",
        "        if verbose:\n",
        "            print(\"expand_parents_with_more_chunks is ON, per_parent_chunks =\", policy.expand_chunks_per_parent_detail)\n",
        "        df_detail = expand_parents_with_more_chunks(\n",
        "            df_prod_one_chunk=df_detail_base.head(1),\n",
        "            client=client,\n",
        "            embed_query_fn=embed_query,\n",
        "            query=query,\n",
        "            per_parent_chunks=policy.expand_chunks_per_parent_detail,\n",
        "            price_gte=None,\n",
        "            price_lte=None,\n",
        "        )\n",
        "    else:\n",
        "        df_detail = df_detail_base\n",
        "    if verbose:\n",
        "        print(\"df_detail shape (after possible expand):\", df_detail.shape)\n",
        "    df_ctx = _trim_budget(\n",
        "        df_detail,\n",
        "        policy.token_budget_est_product_detail,\n",
        "        policy.per_item_char_budget_product_detail,\n",
        "    )\n",
        "    if verbose:\n",
        "        print(\"df_ctx (product detail) shape:\", df_ctx.shape)\n",
        "    ctx = format_context_for_llm_product_detail(df_ctx)\n",
        "    main_title, main_url = extract_main_title_url(df_ctx)\n",
        "    if not has_fact_for_query(query, ctx):\n",
        "        if verbose:\n",
        "            print(\"has_fact_for_query = False → dùng NO-INFO answer\")\n",
        "        answer = generate_product_detail_noinfo_answer(\n",
        "            llm=llm,\n",
        "            query=query,\n",
        "            product_title=main_title,\n",
        "            product_url=main_url,\n",
        "        )\n",
        "        if main_url:\n",
        "            answer = answer.rstrip() + f\"\\n\\nTham khảo thêm tại: {main_url}\"\n",
        "        target = effective_target\n",
        "        return target, df_ctx, answer\n",
        "    answer_raw = generate_product_detail_answer(\n",
        "        llm=llm,\n",
        "        query=query,\n",
        "        context=ctx,\n",
        "        max_new_tokens=320,\n",
        "    )\n",
        "    answer = _clean_detail_answer(answer_raw) if '_clean_detail_answer' in globals() else answer_raw\n",
        "    if main_url:\n",
        "        answer = answer.rstrip() + f\"\\n\\nTham khảo tại: {main_url}\"\n",
        "    target = effective_target\n",
        "    return target, df_ctx, answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model and file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_lookup = build_parent_lookup(\"products_chunked.enriched.jsonl\")\n",
        "parent_lookup_rev = {v: k for k, v in parent_lookup.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q_model = SentenceTransformer(\"BAAI/bge-m3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_index = ParentBM25Index.load(\"bm25_parent_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UBFWVpD2YpJ"
      },
      "outputs": [],
      "source": [
        "llm_cfg = LLMConfig()\n",
        "llm = load_llm(llm_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntYy_zEaenQn"
      },
      "outputs": [],
      "source": [
        "policy = AnswerPolicy(\n",
        "    min_results_product=1,\n",
        "    min_results_faq=1,\n",
        "    min_score_faq=0.4,\n",
        "    min_score_product=0.4,\n",
        "    allow_expand_chunks_detail=False,\n",
        "    expand_chunks_per_parent_detail=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test & debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4XQYO-_eq8f"
      },
      "outputs": [],
      "source": [
        "target, df_ctx, answer = answer_with_rag(\n",
        "    llm=llm,\n",
        "    client=client,\n",
        "    bm25_index=bm25_index,\n",
        "    query=\"Tiki xu là gì\",\n",
        "    search_fn=search_auto_hybrid,\n",
        "    parent_lookup=parent_lookup,\n",
        "    parent_lookup_rev=parent_lookup_rev,\n",
        "    policy=policy,\n",
        "    topk=3,\n",
        "    rrf_lambda=0.8,\n",
        "    per_parent_chunks=1,\n",
        "    verbose=False\n",
        ")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNwpRT5vM2qy"
      },
      "outputs": [],
      "source": [
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_6gnnwhetOi"
      },
      "outputs": [],
      "source": [
        "df_ctx.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igGI4_vuf5HM"
      },
      "outputs": [],
      "source": [
        "df_ctx.to_csv(\"debug.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
