{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", trust_remote_code=True, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a916a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc632fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "MODEL_PATH = \"\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",        \n",
    "    torch_dtype=torch.float32,      \n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00514ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD token fixed: <|endoftext|> 151643\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "MODEL_PATH = \"\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    if tokenizer.eos_token is not None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    elif tokenizer.bos_token is not None:\n",
    "        tokenizer.pad_token = tokenizer.bos_token\n",
    "    else:\n",
    "        tokenizer.pad_token = tokenizer.unk_token or \"<|endoftext|>\"\n",
    "\n",
    "pad_id_list = tokenizer.convert_tokens_to_ids([tokenizer.pad_token])\n",
    "tokenizer.pad_token_id = pad_id_list[0] if isinstance(pad_id_list, list) else pad_id_list\n",
    "\n",
    "print(\"PAD token fixed:\", tokenizer.pad_token, tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                   \n",
    "    lora_alpha=16,         \n",
    "    lora_dropout=0.1,     \n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\n",
    "        \"c_attn\",          \n",
    "        \"c_proj\",         \n",
    "        \"w1\", \"w2\", \"w3\"  \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n",
    "def safe_forward(self, *args, **kwargs):\n",
    "    with torch.cuda.amp.autocast(enabled=False):  \n",
    "        return self._old_forward(*args, **kwargs)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if \"attn\" in name.lower() and hasattr(module, \"forward\"):\n",
    "        module._old_forward = module.forward\n",
    "        module.forward = safe_forward.__get__(module, module.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8152\n",
      "Eval size: 906\n",
      "Columns: ['messages', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']\n",
      "Dataset tokenized: Dataset({\n",
      "    features: ['messages', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 9058\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=r\"tiki_training_dataset.json\")\n",
    "\n",
    "def format_example(example):\n",
    "    messages = example[\"messages\"]\n",
    "    user_message = next((m[\"content\"] for m in messages if m[\"role\"] == \"user\"), \"\")\n",
    "    assistant_message = next((m[\"content\"] for m in messages if m[\"role\"] == \"assistant\"), \"\")\n",
    "    text = f\"### Khách hỏi:\\n{user_message}\\n\\n### Trả lời:\\n{assistant_message}\"\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset[\"train\"].map(format_example)\n",
    "\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Eval size:\", len(eval_dataset))\n",
    "print(\"Columns:\", train_dataset.column_names)\n",
    "\n",
    "\n",
    "print(\"Dataset tokenized:\", tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9eadd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import time\n",
    "\n",
    "class ProgressCallbackCustom(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "\n",
    "        step = state.global_step or 0\n",
    "        total_steps = state.max_steps or 1\n",
    "        epoch = state.epoch or 0\n",
    "\n",
    "       \n",
    "        loss = logs.get(\"loss\", 0) or 0\n",
    "        lr = logs.get(\"learning_rate\", 0) or 0\n",
    "\n",
    "        \n",
    "        elapsed = time.time() - self.start_time\n",
    "        speed = step / elapsed if elapsed > 0 else 0\n",
    "\n",
    "        \n",
    "        eta = (total_steps - step) / speed if speed > 0 else float(\"inf\")\n",
    "\n",
    "        \n",
    "        tqdm.write(\n",
    "            f\"\\rStep {step}/{total_steps} | loss={loss:.4f} | lr={lr:.2e} | epoch={epoch:.2f} | \"\n",
    "            f\"{speed:.2f} it/s | ETA={eta/60:.1f} min\",\n",
    "            end=\"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3291317",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=r\"C:\\train_ouput\",\n",
    "    per_device_train_batch_size=1,\n",
    "    overwrite_output_dir=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=False,\n",
    "    fp16=False,\n",
    "    logging_steps=800,\n",
    "    report_to=\"none\",\n",
    "    \n",
    "    \n",
    "    resume_from_checkpoint=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=800,\n",
    "    save_strategy=\"no\",      \n",
    "    save_safetensors=True,   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716e1222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\.cache\\huggingface\\modules\\transformers_modules\\fa6e214ccbbc6a55235c26ef406355b6bfdf5eed\\modeling_qwen.py:528: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = F.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(input_ids=torch.randint(0, tokenizer.vocab_size, (1, 10)).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2469f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xóa thư mục output cũ, sẵn sàng train mới!\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "output_dir = r\"C:\\train_ouput\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)  \n",
    "print(\"Đã xóa thư mục output cũ, sẵn sàng train mới!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97690916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 800/6792 [12:57<1:37:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800/6792 | loss=0.0788 | lr=1.76e-04 | epoch=0.35 | 1.03 it/s | ETA=97.1 min{'loss': 0.0788, 'learning_rate': 0.00017644287396937575, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 800/6792 [16:29<1:37:03,  1.03it/s]\n",
      " 12%|█▏        | 800/6792 [16:29<1:37:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800/6792 | loss=0.0000 | lr=0.00e+00 | epoch=0.35 | 0.81 it/s | ETA=123.6 min{'eval_loss': 0.06640625, 'eval_runtime': 212.1745, 'eval_samples_per_second': 4.27, 'eval_steps_per_second': 0.537, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 1600/6792 [29:27<1:24:14,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600/6792 | loss=0.0674 | lr=1.53e-04 | epoch=0.71 | 0.91 it/s | ETA=95.6 min{'loss': 0.0674, 'learning_rate': 0.00015288574793875147, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 1600/6792 [32:57<1:24:14,  1.03it/s]\n",
      " 24%|██▎       | 1600/6792 [32:57<1:24:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600/6792 | loss=0.0000 | lr=0.00e+00 | epoch=0.71 | 0.81 it/s | ETA=107.0 min{'eval_loss': 0.05069555714726448, 'eval_runtime': 210.7599, 'eval_samples_per_second': 4.299, 'eval_steps_per_second': 0.541, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 2400/6792 [45:55<1:11:07,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400/6792 | loss=0.0525 | lr=1.29e-04 | epoch=1.06 | 0.87 it/s | ETA=84.1 min{'loss': 0.0525, 'learning_rate': 0.00012932862190812722, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 2400/6792 [49:26<1:11:07,  1.03it/s]\n",
      " 35%|███▌      | 2400/6792 [49:26<1:11:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400/6792 | loss=0.0000 | lr=0.00e+00 | epoch=1.06 | 0.81 it/s | ETA=90.5 min{'eval_loss': 0.0417838878929615, 'eval_runtime': 210.8874, 'eval_samples_per_second': 4.296, 'eval_steps_per_second': 0.541, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 3200/6792 [1:02:24<58:08,  1.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200/6792 | loss=0.0413 | lr=1.06e-04 | epoch=1.41 | 0.85 it/s | ETA=70.1 min{'loss': 0.0413, 'learning_rate': 0.00010577149587750295, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 3200/6792 [1:05:55<58:08,  1.03it/s]\n",
      " 47%|████▋     | 3200/6792 [1:05:55<58:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200/6792 | loss=0.0000 | lr=0.00e+00 | epoch=1.41 | 0.81 it/s | ETA=74.0 min{'eval_loss': 0.03741064295172691, 'eval_runtime': 210.7703, 'eval_samples_per_second': 4.299, 'eval_steps_per_second': 0.541, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 4000/6792 [1:18:53<45:16,  1.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000/6792 | loss=0.0390 | lr=8.22e-05 | epoch=1.77 | 0.84 it/s | ETA=55.1 min{'loss': 0.039, 'learning_rate': 8.221436984687868e-05, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 4000/6792 [1:22:23<45:16,  1.03it/s]\n",
      " 59%|█████▉    | 4000/6792 [1:22:23<45:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000/6792 | loss=0.0000 | lr=0.00e+00 | epoch=1.77 | 0.81 it/s | ETA=57.5 min{'eval_loss': 0.03368871286511421, 'eval_runtime': 210.8388, 'eval_samples_per_second': 4.297, 'eval_steps_per_second': 0.541, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 4800/6792 [1:35:21<32:21,  1.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4800/6792 | loss=0.0378 | lr=5.87e-05 | epoch=2.12 | 0.84 it/s | ETA=39.6 min{'loss': 0.0378, 'learning_rate': 5.8657243816254415e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 4800/6792 [1:38:52<32:21,  1.03it/s]\n",
      " 71%|███████   | 4800/6792 [1:38:52<32:21,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4800/6792 | loss=0.0000 | lr=0.00e+00 | epoch=2.12 | 0.81 it/s | ETA=41.0 min{'eval_loss': 0.031917210668325424, 'eval_runtime': 210.5355, 'eval_samples_per_second': 4.303, 'eval_steps_per_second': 0.541, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 5600/6792 [1:51:49<19:17,  1.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5600/6792 | loss=0.0335 | lr=3.51e-05 | epoch=2.47 | 0.83 it/s | ETA=23.8 min{'loss': 0.0335, 'learning_rate': 3.510011778563015e-05, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 5600/6792 [1:55:20<19:17,  1.03it/s]\n",
      " 82%|████████▏ | 5600/6792 [1:55:20<19:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5600/6792 | loss=0.0000 | lr=0.00e+00 | epoch=2.47 | 0.81 it/s | ETA=24.6 min{'eval_loss': 0.03123464062809944, 'eval_runtime': 210.5136, 'eval_samples_per_second': 4.304, 'eval_steps_per_second': 0.542, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 6400/6792 [2:08:17<06:20,  1.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6400/6792 | loss=0.0328 | lr=1.15e-05 | epoch=2.83 | 0.83 it/s | ETA=7.9 min{'loss': 0.0328, 'learning_rate': 1.154299175500589e-05, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 6400/6792 [2:11:47<06:20,  1.03it/s]\n",
      " 94%|█████████▍| 6400/6792 [2:11:47<06:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6400/6792 | loss=0.0000 | lr=0.00e+00 | epoch=2.83 | 0.81 it/s | ETA=8.1 min{'eval_loss': 0.030994271859526634, 'eval_runtime': 210.4773, 'eval_samples_per_second': 4.305, 'eval_steps_per_second': 0.542, 'epoch': 2.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6792/6792 [2:18:08<00:00,  1.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6792/6792 | loss=0.0000 | lr=0.00e+00 | epoch=3.00 | 0.82 it/s | ETA=0.0 min{'train_runtime': 8288.7461, 'train_samples_per_second': 3.278, 'train_steps_per_second': 0.819, 'train_loss': 0.0469944979754157, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6792, training_loss=0.0469944979754157, metrics={'train_runtime': 8288.7461, 'train_samples_per_second': 3.278, 'train_steps_per_second': 0.819, 'train_loss': 0.0469944979754157, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[ProgressCallbackCustom]  \n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./qwen-lora-finetuned\")\n",
    "tokenizer.save_pretrained(\"./qwen-lora-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c61ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [03:30<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6792/6792 | loss=0.0000 | lr=0.00e+00 | epoch=3.00 | 0.59 it/s | ETA=0.0 min{'eval_loss': 0.03098025918006897, 'eval_runtime': 210.9383, 'eval_samples_per_second': 4.295, 'eval_steps_per_second': 0.54, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbca7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
